{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gneur\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\gneur\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vintage', 'country', 'description', 'points', 'price', 'province',\n",
       "       'region_1', 'taster_name', 'variety', 'winery',\n",
       "       'similarityTop3WinesByVariety', 'word_count', 'tf_grouped_1',\n",
       "       'tf_grouped_2', 'tf_grouped_3', 'tfIdf_grouped_1', 'tfIdf_grouped_2',\n",
       "       'tfIdf_grouped_3', 'tf_fullData_1', 'tf_fullData_2', 'tf_fullData_3',\n",
       "       'tfIdf_fullData_1', 'tfIdf_fullData_2', 'tfIdf_fullData_3', 'pr_5',\n",
       "       'pr_6', 'pr_7', 'pr_8', 'pr_9', 'tas_5', 'tas_6', 'tas_7', 'tas_8',\n",
       "       'tas_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_base = pd.read_csv(\"Our_dataset/StemmedWord2vecTop3_parsed_weather_labeled.csv\", index_col=0) \n",
    "wine_base = wine_base.reset_index()\n",
    "wine_base= wine_base[pd.notnull(wine_base['description'])]\n",
    "wine_base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 5))\n",
    "sns.distplot(wine_base[\"points\"],hist=True,bins = 20,hist_kws={'edgecolor':'black'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE NUMBER OF BINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#right number of bins\n",
    "\n",
    "c= 1 + (10/3)*math.log10(20)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80.,  87.,  90., 100.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = wine_base['points'].copy()\n",
    "#DECIDE NUMBER OF BINS \n",
    "\n",
    "nbins  = 3\n",
    "labels=[\"low\",\"medium\",\"high\"]\n",
    "#nbins  = 4\n",
    "#labels=[\"low\",\"medium\",\"high\",\"very_high\"]\n",
    "#nbins = 5\n",
    "#labels=[\"very_low\", \"low\", \"medium\",\"high\",\"very_high\"]\n",
    "#bin identici \n",
    "#Y,bins = pd.cut(Y,nbins,labels=labels,retbins=True,include_lowest=True,right=True)\n",
    "#quartile\n",
    "Y,bins = pd.qcut(Y,nbins,labels=labels,retbins=True)  \n",
    "values = Y.tolist()  \n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'seaborn' from 'C:\\\\Users\\\\gneur\\\\Anaconda3\\\\lib\\\\site-packages\\\\seaborn\\\\__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 5))\n",
    "for i in range(1,len(bins)-1):\n",
    "\n",
    "    if i == 1:\n",
    "        a = wine_base[wine_base[\"points\"] <= bins[i]]\n",
    "        n =  bins[i]-80\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "        g =+n\n",
    "    if i == len(bins)-1:\n",
    "        a = wine_base[wine_base[\"points\"] > bins[i]]\n",
    "        n = 100 - bins[i]\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "        g =+ n\n",
    "    else:\n",
    "        n = bins[i+1] - bins[i]\n",
    "        g =+n\n",
    "        a = wine_base[(wine_base[\"points\"] > bins[i]) & (wine_base[\"points\"] <= bins[i+1])]\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "ax.set(xticks=wine_base[\"points\"].unique())\n",
    "print(g)\n",
    "sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic = [\"price\",'vintage', 'country', 'province', 'region_1', 'taster_name', 'variety','winery']\n",
    "word = [\"word_count\"]\n",
    "tfGroup = ['tf_grouped_1','tf_grouped_2', 'tf_grouped_3']\n",
    "tfIdfGroup = ['tfIdf_grouped_1', 'tfIdf_grouped_2', 'tfIdf_grouped_3']\n",
    "tfFull = ['tf_fullData_1', 'tf_fullData_2', 'tf_fullData_3',]\n",
    "tfIdfFull = ['tfIdf_fullData_1', 'tfIdf_fullData_2', 'tfIdf_fullData_3']\n",
    "#weather = ['pr_5', 'pr_6', 'pr_7', 'pr_8', 'pr_9', 'tas_5', 'tas_6', 'tas_7', 'tas_8', 'tas_9']# don't really care bcs 0 improvements\n",
    "word2vec = ['similarityTop3WinesByVariety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'vintage', 'country', 'province', 'region_1', 'taster_name',\n",
       "       'variety', 'winery', 'word_count', 'tf_grouped_1', 'tf_grouped_2',\n",
       "       'tf_grouped_3', 'similarityTop3WinesByVariety'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = basic + word + tfGroup + word2vec\n",
    "X = wine_base.loc[:,features]\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUMMY CLASSIFIER = BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = wine_base.loc[:,features]\n",
    "test_size = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "#classifier = DecisionTreeClassifier()\n",
    "classifier = DummyClassifier(\"stratified\")\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)  \n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "#get feature importances\n",
    "#lista\n",
    "#for name, importance in zip(features, classifier.feature_importances_):\n",
    " #   lista.append([name, importance])\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file = open(\"dummyClassifier.txt\",\"a\")\n",
    "file.write(\"Decision Tree Classifier with points divided into \" + str(bins) + \" bins \\n\")\n",
    "file.write(\"Built on: \" + str(features) + \"\\n\")\n",
    "file.write(\"Test size: \" + str(test_size) + \"\\n\")\n",
    "file.write(\"   \" +\"accuracy \" + str(acc) + \"\\n\")\n",
    "file.write(\"   \" +\"weightedPrec \" + str(weightedPrec) + \"\\n\")\n",
    "#file.write(\"Feature importances: \\n\")\n",
    "#for el in lista: \n",
    "#file.write(\"   \" + el[0] + \":   \" + str(el[1]) + \"\\n\")\n",
    "file.write(\"Report By predicted class: \\n\")\n",
    "file.write(classification_report(y_test, y_pred, target_names=labels))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"decTree\" #\"randomForest\" o \"decTree\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algorithm == \"decTree\":\n",
    "    parameters={'max_depth': np.arange(2,10)}#'min_samples_split' : np.arange(10,500,20)}\n",
    "    clf_tree=DecisionTreeClassifier()\n",
    "else: \n",
    "    parameters={'max_depth': np.arange(2,7),\"n_estimators\":[2,3,4,5,6,7,8,9,10]}#'min_samples_split' : np.arange(10,500,20)}\n",
    "    clf_tree = RandomForestClassifier()\n",
    "\n",
    "clf= GridSearchCV(clf_tree,parameters)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best parameters for \" + algorithm + \"points variable binnned by: \" + str(bins))\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 4\n",
    "estimators = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.30 #non va in overfitting, si vede dal grafico sotto\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "if algorithm == \"decTree\":\n",
    "    classifier = DecisionTreeClassifier(max_depth=depth)\n",
    "    print(\"Results obtained by \" + algorithm + \" with depth \" + str(depth))\n",
    "else:\n",
    "    classifier = RandomForestClassifier(max_depth=depth,n_estimators = estimators)\n",
    "    print(\"Results obtained by \" + algorithm + \" with depth \" + str(depth) + \"n_estimators = \" +str(estimators))\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)  \n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "#get feature importances\n",
    "lista = []\n",
    "for name, importance in zip(features, classifier.feature_importances_):\n",
    "    lista.append([name, importance])\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(classifier, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "feature_idx = model.get_support()\n",
    "temp = []\n",
    "for i in range(0,len(feature_idx)): \n",
    "    if feature_idx[i]:\n",
    "        temp.append(i)\n",
    "print(temp)\n",
    "selFeatures = []\n",
    "for i in range(0,len(temp)):\n",
    "    selFeatures.append(features[temp[i]])\n",
    "selFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, Y, test_size=test_size, random_state=42)\n",
    "if algorithm == \"decTree\":\n",
    "    classifier=DecisionTreeClassifier(max_depth=depth)\n",
    "    print(\"Results obtained by \" + algorithm + \" with depth \" + str(depth))\n",
    "else: \n",
    "    classifier = RandomForestClassifier(max_depth=depth,n_estimators = estimators)\n",
    "    print(\"Results obtained by \" + algorithm + \" with depth \" + str(depth) + \"and N_estimators = \" + str(estimators))\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred =classifier.predict(X_test)  \n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "def conda_fix(graph):\n",
    "        path = os.path.join(sys.base_exec_prefix, \"Library\", \"bin\", \"graphviz\")\n",
    "        paths = (\"dot\", \"twopi\", \"neato\", \"circo\", \"fdp\")\n",
    "        paths = {p: os.path.join(path, \"{}.exe\".format(p)) for p in paths}\n",
    "        graph.set_graphviz_executables(paths)\n",
    "import pydotplus \n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "dot_data = tree.export_graphviz(classifier, out_file=None, \n",
    "                         feature_names=selFeatures,  \n",
    "                         class_names=labels,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "conda_fix(graph)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check AUC, feature selection, and data with sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same only add everything into a data frame so that you already have there everything you can plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file = open(\"classification\" + str(bins) + \"bins.txt\",\"a\")\n",
    "file.write(\"Decision Tree Classifier with points divided into \" + str(bins) + \" bins \\n\")\n",
    "file.write(\"Built on: \" + str(features) + \"\\n\")\n",
    "file.write(\"Test size: \" + str(test_size) + \"\\n\")\n",
    "file.write(\"   \" +\"accuracy \" + str(acc) + \"\\n\")\n",
    "file.write(\"   \" +\"weightedPrec \" + str(weightedPrec) + \"\\n\")\n",
    "file.write(\"Feature importances: \\n\")\n",
    "for el in lista: \n",
    "    file.write(\"   \" + el[0] + \":   \" + str(el[1]) + \"\\n\")\n",
    "file.write(\"Report By predicted class: \\n\")\n",
    "file.write(classification_report(y_test, y_pred, target_names=labels))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check learning curves\n",
    "train_sizes, train_scores, test_scores = learning_curve(DecisionTreeClassifier(max_depth=3), \n",
    "                                                        X, \n",
    "                                                        Y,\n",
    "                                                        # Number of folds in cross-validation\n",
    "                                                        cv=10,\n",
    "                                                        # Evaluation metric\n",
    "                                                        scoring='accuracy',\n",
    "                                                        # Use all computer cores\n",
    "                                                        n_jobs=-1, \n",
    "                                                        # 50 different sizes of the training set\n",
    "                                                        train_sizes=np.linspace(0.01, 1.0, 50))\n",
    "\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "plt.subplots(figsize = (12, 5))\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"red\",alpha = 0.5)\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"blue\",alpha = 0.5)\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [[\"price\"],[\"price\",\"word_count\"],basic,basic+tfGroup, basic+word2vec,basic+word2vec+tfGroup,word2vec,tfGroup,word2vec+tfGroup]\n",
    "allfeatures = basic + word + word2vec + tfGroup \n",
    "decTreeCombinations = {\"depth\":[2,3,4,5],\"args\":args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modificala per usare anche il random forest a modo\n",
    "def testToDataFrame(algorithm,combination,Y,allfeats,dataset):\n",
    "    test_size = 0.30 #non va in overfitting, si vede dal grafico sotto\n",
    "    cols = [\"algorithm\",\"input\",\"precision\",\"accuracy\",\"depth\"]\n",
    "    for el in features:\n",
    "        cols.append(\"feat_\"+el)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    row = 0\n",
    "    comb = 0\n",
    "    for el in combination[\"args\"]: \n",
    "        for depth in combination[\"depth\"]:\n",
    "            row = row + 1\n",
    "            X = dataset.loc[:,el]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "            if algorithm == \"decTree\":\n",
    "                classifier = DecisionTreeClassifier(max_depth=depth)\n",
    "            else:\n",
    "                classifier = RandomForestClassifier(max_depth=depth,n_estimators = estimators)\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_pred = classifier.predict(X_test)  \n",
    "            acc = accuracy_score(y_test,y_pred)\n",
    "            weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "            data = [algorithm,el,weightedPrec,acc,depth]\n",
    "            temp = {}\n",
    "            c = zip(el,classifier.feature_importances_)\n",
    "            for name,importance in c:\n",
    "                temp[name] = importance\n",
    "            for feat in allfeats:\n",
    "                if feat not in el:\n",
    "                    data.append(0)\n",
    "                else:\n",
    "                    data.append(temp[feat])\n",
    "            df2 = pd.DataFrame([data],columns=cols)\n",
    "            results = results.append(df2,ignore_index=True)\n",
    "        comb = comb + 1\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gneur\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\gneur\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\gneur\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "res = testToDataFrame(\"decTree\",decTreeCombinations,Y,allfeatures,wine_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>input</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>depth</th>\n",
       "      <th>feat_price</th>\n",
       "      <th>feat_vintage</th>\n",
       "      <th>feat_country</th>\n",
       "      <th>feat_province</th>\n",
       "      <th>feat_region_1</th>\n",
       "      <th>feat_taster_name</th>\n",
       "      <th>feat_variety</th>\n",
       "      <th>feat_winery</th>\n",
       "      <th>feat_word_count</th>\n",
       "      <th>feat_tf_grouped_1</th>\n",
       "      <th>feat_tf_grouped_2</th>\n",
       "      <th>feat_tf_grouped_3</th>\n",
       "      <th>feat_similarityTop3WinesByVariety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.594490</td>\n",
       "      <td>0.586792</td>\n",
       "      <td>5</td>\n",
       "      <td>0.817221</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.591351</td>\n",
       "      <td>0.560194</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.591351</td>\n",
       "      <td>0.560194</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, word_count]</td>\n",
       "      <td>0.590381</td>\n",
       "      <td>0.584156</td>\n",
       "      <td>4</td>\n",
       "      <td>0.799292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.589666</td>\n",
       "      <td>0.561133</td>\n",
       "      <td>3</td>\n",
       "      <td>0.933613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.589666</td>\n",
       "      <td>0.561133</td>\n",
       "      <td>3</td>\n",
       "      <td>0.933613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.585664</td>\n",
       "      <td>0.585338</td>\n",
       "      <td>5</td>\n",
       "      <td>0.816830</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.077197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.584160</td>\n",
       "      <td>0.577249</td>\n",
       "      <td>4</td>\n",
       "      <td>0.848151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.584160</td>\n",
       "      <td>0.577249</td>\n",
       "      <td>4</td>\n",
       "      <td>0.848151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, word_count]</td>\n",
       "      <td>0.579146</td>\n",
       "      <td>0.576280</td>\n",
       "      <td>3</td>\n",
       "      <td>0.852276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, word_count]</td>\n",
       "      <td>0.574274</td>\n",
       "      <td>0.586580</td>\n",
       "      <td>5</td>\n",
       "      <td>0.791020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.572107</td>\n",
       "      <td>0.575098</td>\n",
       "      <td>5</td>\n",
       "      <td>0.876718</td>\n",
       "      <td>0.010475</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.076321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007352</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.009550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.571136</td>\n",
       "      <td>0.575977</td>\n",
       "      <td>5</td>\n",
       "      <td>0.887522</td>\n",
       "      <td>0.012910</td>\n",
       "      <td>0.011947</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>0.079674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.561288</td>\n",
       "      <td>0.573826</td>\n",
       "      <td>4</td>\n",
       "      <td>0.907991</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.011021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.561288</td>\n",
       "      <td>0.573826</td>\n",
       "      <td>4</td>\n",
       "      <td>0.907991</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.011021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price]</td>\n",
       "      <td>0.552437</td>\n",
       "      <td>0.552105</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price]</td>\n",
       "      <td>0.552394</td>\n",
       "      <td>0.552075</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price]</td>\n",
       "      <td>0.552394</td>\n",
       "      <td>0.552075</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price]</td>\n",
       "      <td>0.532370</td>\n",
       "      <td>0.543017</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, word_count]</td>\n",
       "      <td>0.532370</td>\n",
       "      <td>0.543017</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.532370</td>\n",
       "      <td>0.543017</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.532370</td>\n",
       "      <td>0.543017</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.532370</td>\n",
       "      <td>0.543017</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[price, vintage, country, province, region_1, ...</td>\n",
       "      <td>0.532370</td>\n",
       "      <td>0.543017</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.450947</td>\n",
       "      <td>0.475704</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665976</td>\n",
       "      <td>0.037656</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.288868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.449335</td>\n",
       "      <td>0.469918</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692555</td>\n",
       "      <td>0.019124</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.280056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.439326</td>\n",
       "      <td>0.462072</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[similarityTop3WinesByVariety]</td>\n",
       "      <td>0.424667</td>\n",
       "      <td>0.436746</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3]</td>\n",
       "      <td>0.419484</td>\n",
       "      <td>0.434505</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297356</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.692862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[similarityTop3WinesByVariety]</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>0.430354</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[similarityTop3WinesByVariety]</td>\n",
       "      <td>0.411797</td>\n",
       "      <td>0.430294</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3]</td>\n",
       "      <td>0.407513</td>\n",
       "      <td>0.429294</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242303</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.749250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3]</td>\n",
       "      <td>0.387907</td>\n",
       "      <td>0.419358</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.844181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.294139</td>\n",
       "      <td>0.445532</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.723387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[similarityTop3WinesByVariety]</td>\n",
       "      <td>0.278901</td>\n",
       "      <td>0.421236</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>decTree</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3]</td>\n",
       "      <td>0.274295</td>\n",
       "      <td>0.417995</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithm                                              input  precision  \\\n",
       "19   decTree  [price, vintage, country, province, region_1, ...   0.594490   \n",
       "17   decTree  [price, vintage, country, province, region_1, ...   0.591351   \n",
       "21   decTree  [price, vintage, country, province, region_1, ...   0.591351   \n",
       "6    decTree                                [price, word_count]   0.590381   \n",
       "9    decTree  [price, vintage, country, province, region_1, ...   0.589666   \n",
       "13   decTree  [price, vintage, country, province, region_1, ...   0.589666   \n",
       "23   decTree  [price, vintage, country, province, region_1, ...   0.585664   \n",
       "18   decTree  [price, vintage, country, province, region_1, ...   0.584160   \n",
       "22   decTree  [price, vintage, country, province, region_1, ...   0.584160   \n",
       "5    decTree                                [price, word_count]   0.579146   \n",
       "7    decTree                                [price, word_count]   0.574274   \n",
       "15   decTree  [price, vintage, country, province, region_1, ...   0.572107   \n",
       "11   decTree  [price, vintage, country, province, region_1, ...   0.571136   \n",
       "10   decTree  [price, vintage, country, province, region_1, ...   0.561288   \n",
       "14   decTree  [price, vintage, country, province, region_1, ...   0.561288   \n",
       "3    decTree                                            [price]   0.552437   \n",
       "2    decTree                                            [price]   0.552394   \n",
       "1    decTree                                            [price]   0.552394   \n",
       "0    decTree                                            [price]   0.532370   \n",
       "4    decTree                                [price, word_count]   0.532370   \n",
       "8    decTree  [price, vintage, country, province, region_1, ...   0.532370   \n",
       "12   decTree  [price, vintage, country, province, region_1, ...   0.532370   \n",
       "16   decTree  [price, vintage, country, province, region_1, ...   0.532370   \n",
       "20   decTree  [price, vintage, country, province, region_1, ...   0.532370   \n",
       "35   decTree  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.450947   \n",
       "34   decTree  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.449335   \n",
       "33   decTree  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.439326   \n",
       "25   decTree                     [similarityTop3WinesByVariety]   0.424667   \n",
       "31   decTree         [tf_grouped_1, tf_grouped_2, tf_grouped_3]   0.419484   \n",
       "27   decTree                     [similarityTop3WinesByVariety]   0.412200   \n",
       "26   decTree                     [similarityTop3WinesByVariety]   0.411797   \n",
       "30   decTree         [tf_grouped_1, tf_grouped_2, tf_grouped_3]   0.407513   \n",
       "29   decTree         [tf_grouped_1, tf_grouped_2, tf_grouped_3]   0.387907   \n",
       "32   decTree  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.294139   \n",
       "24   decTree                     [similarityTop3WinesByVariety]   0.278901   \n",
       "28   decTree         [tf_grouped_1, tf_grouped_2, tf_grouped_3]   0.274295   \n",
       "\n",
       "    accuracy  depth  feat_price  feat_vintage  feat_country  feat_province  \\\n",
       "19  0.586792      5    0.817221      0.005686      0.002884       0.000000   \n",
       "17  0.560194      3    0.925955      0.000000      0.000000       0.000000   \n",
       "21  0.560194      3    0.925955      0.000000      0.000000       0.000000   \n",
       "6   0.584156      4    0.799292      0.000000      0.000000       0.000000   \n",
       "9   0.561133      3    0.933613      0.000000      0.000000       0.000000   \n",
       "13  0.561133      3    0.933613      0.000000      0.000000       0.000000   \n",
       "23  0.585338      5    0.816830      0.005683      0.002882       0.000000   \n",
       "18  0.577249      4    0.848151      0.000000      0.000000       0.000000   \n",
       "22  0.577249      4    0.848151      0.000000      0.000000       0.000000   \n",
       "5   0.576280      3    0.852276      0.000000      0.000000       0.000000   \n",
       "7   0.586580      5    0.791020      0.000000      0.000000       0.000000   \n",
       "15  0.575098      5    0.876718      0.010475      0.011874       0.001987   \n",
       "11  0.575977      5    0.887522      0.012910      0.011947       0.001999   \n",
       "10  0.573826      4    0.907991      0.008398      0.011021       0.000000   \n",
       "14  0.573826      4    0.907991      0.008398      0.011021       0.000000   \n",
       "3   0.552105      5    1.000000      0.000000      0.000000       0.000000   \n",
       "2   0.552075      4    1.000000      0.000000      0.000000       0.000000   \n",
       "1   0.552075      3    1.000000      0.000000      0.000000       0.000000   \n",
       "0   0.543017      2    1.000000      0.000000      0.000000       0.000000   \n",
       "4   0.543017      2    1.000000      0.000000      0.000000       0.000000   \n",
       "8   0.543017      2    1.000000      0.000000      0.000000       0.000000   \n",
       "12  0.543017      2    1.000000      0.000000      0.000000       0.000000   \n",
       "16  0.543017      2    1.000000      0.000000      0.000000       0.000000   \n",
       "20  0.543017      2    1.000000      0.000000      0.000000       0.000000   \n",
       "35  0.475704      5    0.000000      0.000000      0.000000       0.000000   \n",
       "34  0.469918      4    0.000000      0.000000      0.000000       0.000000   \n",
       "33  0.462072      3    0.000000      0.000000      0.000000       0.000000   \n",
       "25  0.436746      3    0.000000      0.000000      0.000000       0.000000   \n",
       "31  0.434505      5    0.000000      0.000000      0.000000       0.000000   \n",
       "27  0.430354      5    0.000000      0.000000      0.000000       0.000000   \n",
       "26  0.430294      4    0.000000      0.000000      0.000000       0.000000   \n",
       "30  0.429294      4    0.000000      0.000000      0.000000       0.000000   \n",
       "29  0.419358      3    0.000000      0.000000      0.000000       0.000000   \n",
       "32  0.445532      2    0.000000      0.000000      0.000000       0.000000   \n",
       "24  0.421236      2    0.000000      0.000000      0.000000       0.000000   \n",
       "28  0.417995      2    0.000000      0.000000      0.000000       0.000000   \n",
       "\n",
       "    feat_region_1  feat_taster_name  feat_variety  feat_winery  \\\n",
       "19       0.001383          0.080200           0.0          0.0   \n",
       "17       0.000000          0.044993           0.0          0.0   \n",
       "21       0.000000          0.044993           0.0          0.0   \n",
       "6        0.000000          0.000000           0.0          0.0   \n",
       "9        0.000000          0.066387           0.0          0.0   \n",
       "13       0.000000          0.066387           0.0          0.0   \n",
       "23       0.001383          0.077197           0.0          0.0   \n",
       "18       0.000000          0.069646           0.0          0.0   \n",
       "22       0.000000          0.069646           0.0          0.0   \n",
       "5        0.000000          0.000000           0.0          0.0   \n",
       "7        0.000000          0.000000           0.0          0.0   \n",
       "15       0.003735          0.076321           0.0          0.0   \n",
       "11       0.005948          0.079674           0.0          0.0   \n",
       "10       0.000000          0.072589           0.0          0.0   \n",
       "14       0.000000          0.072589           0.0          0.0   \n",
       "3        0.000000          0.000000           0.0          0.0   \n",
       "2        0.000000          0.000000           0.0          0.0   \n",
       "1        0.000000          0.000000           0.0          0.0   \n",
       "0        0.000000          0.000000           0.0          0.0   \n",
       "4        0.000000          0.000000           0.0          0.0   \n",
       "8        0.000000          0.000000           0.0          0.0   \n",
       "12       0.000000          0.000000           0.0          0.0   \n",
       "16       0.000000          0.000000           0.0          0.0   \n",
       "20       0.000000          0.000000           0.0          0.0   \n",
       "35       0.000000          0.000000           0.0          0.0   \n",
       "34       0.000000          0.000000           0.0          0.0   \n",
       "33       0.000000          0.000000           0.0          0.0   \n",
       "25       0.000000          0.000000           0.0          0.0   \n",
       "31       0.000000          0.000000           0.0          0.0   \n",
       "27       0.000000          0.000000           0.0          0.0   \n",
       "26       0.000000          0.000000           0.0          0.0   \n",
       "30       0.000000          0.000000           0.0          0.0   \n",
       "29       0.000000          0.000000           0.0          0.0   \n",
       "32       0.000000          0.000000           0.0          0.0   \n",
       "24       0.000000          0.000000           0.0          0.0   \n",
       "28       0.000000          0.000000           0.0          0.0   \n",
       "\n",
       "    feat_word_count  feat_tf_grouped_1  feat_tf_grouped_2  feat_tf_grouped_3  \\\n",
       "19         0.000000           0.092627           0.000000           0.000000   \n",
       "17         0.000000           0.029052           0.000000           0.000000   \n",
       "21         0.000000           0.029052           0.000000           0.000000   \n",
       "6          0.200708           0.000000           0.000000           0.000000   \n",
       "9          0.000000           0.000000           0.000000           0.000000   \n",
       "13         0.000000           0.000000           0.000000           0.000000   \n",
       "23         0.000000           0.091383           0.000000           0.003302   \n",
       "18         0.000000           0.082203           0.000000           0.000000   \n",
       "22         0.000000           0.082203           0.000000           0.000000   \n",
       "5          0.147724           0.000000           0.000000           0.000000   \n",
       "7          0.208980           0.000000           0.000000           0.000000   \n",
       "15         0.000000           0.000000           0.007352           0.001988   \n",
       "11         0.000000           0.000000           0.000000           0.000000   \n",
       "10         0.000000           0.000000           0.000000           0.000000   \n",
       "14         0.000000           0.000000           0.000000           0.000000   \n",
       "3          0.000000           0.000000           0.000000           0.000000   \n",
       "2          0.000000           0.000000           0.000000           0.000000   \n",
       "1          0.000000           0.000000           0.000000           0.000000   \n",
       "0          0.000000           0.000000           0.000000           0.000000   \n",
       "4          0.000000           0.000000           0.000000           0.000000   \n",
       "8          0.000000           0.000000           0.000000           0.000000   \n",
       "12         0.000000           0.000000           0.000000           0.000000   \n",
       "16         0.000000           0.000000           0.000000           0.000000   \n",
       "20         0.000000           0.000000           0.000000           0.000000   \n",
       "35         0.000000           0.665976           0.037656           0.007500   \n",
       "34         0.000000           0.692555           0.019124           0.008264   \n",
       "33         0.000000           0.755105           0.000000           0.000000   \n",
       "25         0.000000           1.000000           0.000000           0.000000   \n",
       "31         0.000000           0.000000           0.297356           0.009782   \n",
       "27         0.000000           1.000000           0.000000           0.000000   \n",
       "26         0.000000           1.000000           0.000000           0.000000   \n",
       "30         0.000000           0.000000           0.242303           0.008447   \n",
       "29         0.000000           0.000000           0.155819           0.000000   \n",
       "32         0.000000           0.723387           0.000000           0.000000   \n",
       "24         0.000000           1.000000           0.000000           0.000000   \n",
       "28         0.000000           0.000000           0.063050           0.000000   \n",
       "\n",
       "    feat_similarityTop3WinesByVariety  \n",
       "19                           0.000000  \n",
       "17                           0.000000  \n",
       "21                           0.000000  \n",
       "6                            0.000000  \n",
       "9                            0.000000  \n",
       "13                           0.000000  \n",
       "23                           0.001340  \n",
       "18                           0.000000  \n",
       "22                           0.000000  \n",
       "5                            0.000000  \n",
       "7                            0.000000  \n",
       "15                           0.009550  \n",
       "11                           0.000000  \n",
       "10                           0.000000  \n",
       "14                           0.000000  \n",
       "3                            0.000000  \n",
       "2                            0.000000  \n",
       "1                            0.000000  \n",
       "0                            0.000000  \n",
       "4                            0.000000  \n",
       "8                            0.000000  \n",
       "12                           0.000000  \n",
       "16                           0.000000  \n",
       "20                           0.000000  \n",
       "35                           0.288868  \n",
       "34                           0.280056  \n",
       "33                           0.244895  \n",
       "25                           0.000000  \n",
       "31                           0.692862  \n",
       "27                           0.000000  \n",
       "26                           0.000000  \n",
       "30                           0.749250  \n",
       "29                           0.844181  \n",
       "32                           0.276613  \n",
       "24                           0.000000  \n",
       "28                           0.936950  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values([\"precision\",'depth'],ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
