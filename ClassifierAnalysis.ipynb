{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score,precision_recall_fscore_support,f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from pandas.tools.plotting import parallel_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vintage', 'country', 'description', 'points', 'price', 'province',\n",
       "       'region_1', 'taster_name', 'variety', 'winery',\n",
       "       'similarityTop3WinesByVariety', 'word_count', 'tf_grouped_1',\n",
       "       'tf_grouped_2', 'tf_grouped_3', 'tfIdf_grouped_1', 'tfIdf_grouped_2',\n",
       "       'tfIdf_grouped_3', 'tf_fullData_1', 'tf_fullData_2', 'tf_fullData_3',\n",
       "       'tfIdf_fullData_1', 'tfIdf_fullData_2', 'tfIdf_fullData_3', 'pr_5',\n",
       "       'pr_6', 'pr_7', 'pr_8', 'pr_9', 'tas_5', 'tas_6', 'tas_7', 'tas_8',\n",
       "       'tas_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_base = pd.read_csv(\"Our_dataset/StemmedWord2vecTop3_parsed_weather_labeled.csv\", index_col=0) \n",
    "wine_base = wine_base.reset_index()\n",
    "wine_base= wine_base[pd.notnull(wine_base['description'])]\n",
    "wine_base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1adfae27e80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAFACAYAAACoSyokAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xl0pHd5J/rvU/uiKqmk0tpSt9Sr3W7jrW12s4XEJhM7ZEwwyZ3gCXPJJYdzMjczN8OccwcSMndySXKHJAcuE+7AQMJwiBMgOMHBIRjjYIzd7V5sy+5FvWpXVUmqfa/f/aPqVaulWt636i2t3885HKT3fet9f922paeeen7PI0opEBERERFRdZbNXgARERER0VbGgJmIiIiIqA4GzEREREREdTBgJiIiIiKqgwEzEREREVEdDJiJiIiIiOpgwExEREREVAcDZiIiIiKiOhgwExERERHVYdvsBawVDAbV6OjoZi+DiIiIiHa4l156KayU6m103ZYLmEdHR3Hy5MnNXgYRERER7XAick3PdSzJICIiIiKqgwEzEREREVEdDJiJiIiIiOpgwExEREREVIeugFlEHhCR8yIyISKfqHL+fhE5JSIFEXlkzbm9IvKPIvK6iLwmIqPmLJ2IiIiIqP0aBswiYgXweQAPAjgK4EMicnTNZdcBPAbg61Vu8RcA/kgpdSuA+wAstLJgIiIiIqKNpKet3H0AJpRSlwFARL4B4GEAr2kXKKWuVs6VVr+wEljblFLfr1yXMGfZREREREQbQ09Jxh4Ak6u+n6oc0+MwgGUR+ZaInBaRP6pkrImIiIiItgU9AbNUOaZ03t8G4O0A/j2AewHsR7l04+YHiHxURE6KyMlQKKTz1kRERERE7acnYJ4CMLLq+2EAMzrvPwXgtFLqslKqAOBvAdy99iKl1BeVUseVUsd7extOJyQiIiIi2jB6AuYTAA6JyJiIOAA8CuAJnfc/ASAgIloU/G6sqn0mItoof3d2Bn/4vXObvQwiItqGGgbMlczwxwE8BeB1AI8rpcZF5NMi8hAAiMi9IjIF4AMA/lxExiuvLaJcjvEDEXkF5fKO/689fxQiotq+/sJ1fPm5KyiV9FaUERERlenpkgGl1JMAnlxz7JOrvj6BcqlGtdd+H8AbWlgjEe0whWIJE6EEbhnwb8jzlFJ4dSaKTL6EhXgWA52uDXkuERHtDJz0R0Qb7omzM3jwT/8Z1yLJDXne5GIa8UwBAHB1g55JREQ7BwNmItpwF+YTUAo4cXVpQ543PhNd+XqjgnQiIto5GDAT0YabXEwBAF66tjEB86szUdgsArtVcDWS2pBnEhHRzqGrhpmIyEzXFstZ3tPXNyhgno7hUL8P2XwRV8PMMBMRkTHMMBPRhrseScFqEZyfjyOeybf1WUopjM9EcWzIj9GglxlmIiIyjAEzEW2o5VQOsUwBbzsYhFLAmcnltj5vIZ5FOJHDbUN+7Ovx4FokCaXYWo6IiPRjwExEG+p6pX75oTuGIAKcutbegPnV6fKGv2N7OjHa40UqV0QokW3rM4mIaGdhwExEG+papSTitj1+HOn34VSb65jHZ2IQAW4dLGeYV6+BiIhIDwbMRLShtAzz3m4P7tobwKnrS22dvvfqdBRjQS+8ThtGe7wAgCvc+EdERAYwYCaiDXU9kkKwwwmPw4a793YhningUijRtueNz8RwbKgTADAccMNmEfZiJiIiQxgwE9GGuraYXCmNuGdfAADaVpaxlMxhejmN24bKI7htVguGA252yiAiIkMYMBPRhppcTGNvdzlgHgt6EfDY2zbAZHwmBqC84U+zr8fLDDMRERnCgJmINky2UMRM9EbALCKVOub2dMp4tTISW8swA8BojwdXwym2liMiIt0YMBPRhpleSkMprATMQLksY2IhgWjK/AEm4zMx7Olyo8vjWDm2r8eLRLaASDJn+vOIiGhnYsBMRBvmWqVDhlbDDAB37e0CAJyeNL8sY3w6imN7/DcdGwuWO2WwLIOIiPRiwExEG2ZyVUs5zR3DXbAIcMrkOuZEtoDL4SRuG+q86bgWrF8Nc+MfERHpw4CZiDbMtUgKLrsFvT7nyjGv04ZbB/2m1zG/Pqtt+Ls5wzwc8MAizDATEZF+DJiJaMNcX0xhb7cHInLT8bv3BnBmchlFEweYrIzEXpNhdtgs2BNw4wpbyxERkU4MmIlow1yPpLC327vu+N37upDIFnBhPm7as16djiHY4USf37Xu3ChbyxERkQEMmIloQyilVjLMa9291/wBJuMz6zf8aUZ7vLgSTrK1HBER6cKAmYg2RCiRRTpfvKlDhmZvtwfBDgdOXTOnjjmTL+LiQuKm/sur7evxIJ4pYLkNreyIiGjnYcBMRBvieqVmeG+VgFkbYHLapAzz+bk4iiW1rn5ZM9pTLgu5yrIMIiLSgQEzEW2I61Vayq22v9eLqaW0KWUSWoeMozUyzKPBSms5BsxERKQDA2Yi2hDXIimIAMMBd9XzvR1O5IolxDKFlp81H8sCAIa6qj9rpNsDEfZiJiIifXQFzCLygIicF5EJEflElfP3i8gpESmIyCNVzvtFZFpEPmfGoolo+5lcTGHQ74LTZq16PthR7s0cTmRbflYkmUWXxw67tfqPOKfNiqFONztlEBGRLg0DZhGxAvg8gAcBHAXwIRE5uuay6wAeA/D1Grf5fQA/an6ZRLTdXVtMVa1f1vR0OAAAkUSu5WdFEjn0eB11rxkNenCVvZiJiEgHPRnm+wBMKKUuK6VyAL4B4OHVFyilriqlXgZQWvtiEbkHQD+AfzRhvUS0TdVqKacxM8McSmTR0+Gse80+9mImIiKd9ATMewBMrvp+qnKsIRGxAPh/APwfxpdGRDtFKldAKJ7Fvp71Q0s0ppZkJLLobRAwj/Z4sJTKI8rWckRE1ICegFmqHNO7jf03ATyplJqsd5GIfFRETorIyVAopPPWRLRdTC6mAZQ329XS7XXAIkA4bkYNc26lxKMWtpYjIiK9bDqumQIwsur7YQAzOu//ZgBvF5HfBNABwCEiCaXUTRsHlVJfBPBFADh+/DhHbxHtMFrpw746AbPVIuj2OhBOtlbDnC+WsJzKo8fbIMMcvBEw3zHS1dIzN0s6V8RiKgeLABYRWETgsFnQ6bZv9tKIiHYUPQHzCQCHRGQMwDSARwH8ip6bK6V+VftaRB4DcHxtsExEO1+jHsyaHq+z5QzzYiXgDvrqZ5i1tVzbxhv/fvHzz+H8fHzd8f/+a8fxM0f7N2FFREQ7U8OAWSlVEJGPA3gKgBXAl5VS4yLyaQAnlVJPiMi9AL4NIADgF0Tk95RSt7V15US0bVxfTMHnsqHLUz/zGfQ5Wq5h1l7fKMPsslsx2OnatiUZhWIJFxfieO/Rfrznlj4UlUKxpPDJ74zjtdkYA2YiIhPpyTBDKfUkgCfXHPvkqq9PoFyqUe8eXwHwFcMrJKJt71qk3CFDpNqWiBuCHU6cvr7c0rO0tnTBBjXMANDvdyFkQs30Zgglsigp4F1H+vDofXtXjv/ZDy5iNprexJUREe08nPRHRG03uZjCvjo9mDXBDqdpGeZggy4ZQHmj4WKLNdObZTaaAQAMdrpuOj7Q6Vo5R0RE5mDATERtVSwpTC6lsLe7dks5TU+HA6lcEalc8+OxtQxzoy4ZABDwOLC0XQPm5UrA3LUmYPa7MceAmYjIVAyYiait5mIZ5Iuq4YY/4EZWuJVpf+FkFg6bBR3OxhVnPR0OLKa2acBcKbsY9LtvOj7UxQwzEZHZGDATUVvN1SgdqEYbNhJqoSwjHM8h6HU0rJcGyhnmTL6EdK7Y9PM2y1w0A7fdCr/75jcGA50uRNP5lrL0RER0MwbMRNRWWo1wt7dxicTKtL8WNuJFklkEfY3rl8trKnft2I5Z5tloBoNdrnVvDLQ3JswyExGZhwEzEbXVkoGAWas7jrRQVxxJ5NCj41lAOcMMAIstlIBsltloumrWfqBSosE6ZiIi8zBgJqK20oJfPZvwtGtayTCHE1n06OiQAdwI4rdjhnkumlkJjlcb6mKGmYjIbAyYiaitFpNZuOwWeByNN+E5bVb4XbamW8sppRBJ5HS1lANuBMzbrVNGsaQwH8+uBMer9fvLx+bYi5mIyDQMmImorSLJXMOpe6sFfU6EmyyRiGcLyBVLuoaWAKsyzNssYA7FsyiWFAaqlGS47FZ0ex2YYYaZiMg0DJiJqK0Wkzld9cuaYIez6S4ZWimHnvIPAPC77LAIsLTNSjJWWsrV6Dwy4HexhpmIyEQMmImorYwHzA5EmgyYV+qldWa0LRZBwLP9pv3dmPK3voYZYC9mIiKzMWAmorYy0rUC0MZjNxfARgyMxdYEtuF47FpjsTUDnS7WMBMRmYgBMxG11WIyh4DBgDmaziNXKBl+VqgSaOutYQaA7m2YYZ6LpuGyW9Dptlc9P9jpxlIqj0x++w1kISLaihgwE1HbpHNFpPNFwzXMQHkAiVFahtlIgN7tdWy7GuaZaAZDne6a0wwH/GwtR0RkJgbMRNQ2Wn9jIyUZK8NLmijLiCRyCHjssFv1/2grl2TkDT9rM81FM1U7ZGgGV3oxsyyDiMgMDJiJqG20CXrNZJib6ZQRSeofWqLp9tqxlMpBKWX4eZulYcDcyWl/RERmYsBMRG2jlVXobfMGAL2VgLeZaX/huLENhkB5PHaxpBBLFww/bzMUSwpzsXJJRi0sySAiMhcDZiJqG20zXbehwSWV8dhNlGSEk1kEfUYzzNtrPHY4UXtoicbtsKLLY2dJBhGRSRrPqiUiatKNgFl/1tfjsMHjsDY1HjuSyCFY51lf+NJXMBeO3nRsKu8BMIQ//POvoc9mbkZ2INiJj33kMVPv2ailnGaw082SDCIikzBgJqK2iSRzsFsFflf1HzXVAlgAsBT24YcvvozC+Pd1P6uogGj6IM6ePoVPnftB1WteOnMWv/Jvf/emY96lFH7wzCUEb3srjgz6dT9Pj/PPfNvU+wHA7LI25a92SUb5PIeXEBGZhQEzEbXNYiKHgMdRs/3ZXDiKI+98/7rjgWcmYLEFcORtb9H9rGg6D3zvHPbdcjuOjPVUvebZ519cd8zrKP8YTOW2Rw2z3gzzQKcLZyeXN2JJREQ7HmuYiahtIgbHYms6XHYkssYC2GTlep/TWB7A47RWXr89hnzMxTJw2izo8lQfWqIZ9LsQSeY4vISIyAQMmImobZZSTQbMThviBgNmLcD2GgyYHVYLbBZBcptkmGeW0xjqqj20RDPYVS7ZmI+xLIOIqFUMmImobRabzTA7rUhlCygZ6I2sBcwdBgNmEYHHYUVqu2SYo5mVtnH1aCUbrGMmImqdroBZRB4QkfMiMiEin6hy/n4ROSUiBRF5ZNXxO0XkeREZF5GXReSDZi6eiLa2SCJruC8yUA56FYBUTn8Qm2wyYAbKWentkmGejWYa1i8DWGk7x04ZREStaxgwi4gVwOcBPAjgKIAPicjRNZddB/AYgK+vOZ4C8GtKqdsAPADgT0Skq9VFE9HWly+WEMsUDPVg1nS4yvW5iYz+IDaRKcBmEThsxj848zpshoLzzVIsKczHMiujr+thhpmIyDx6UjH3AZhQSl0GABH5BoCHAbymXaCUulo5V1r9QqXUhVVfz4jIAoBeANy6TbTDLWk9mA1M+dNoWWIjG/8S2QI6nLaGtb3VeJxWLC1t/cElkUQWhZLCQIOWckC5n3Wnm8NLiIjMoCcVswfA5KrvpyrHDBGR+wA4AFyqcu6jInJSRE6GQiGjtyaiLShSCZibKcnwVjpXGAmYk7mC4Q1/Gs82yTDPVLLFQzpKMgD2YiYiMouegLlaukb/ThwAIjII4C8B/GulVGnteaXUF5VSx5VSx3t7e43cmoi2qGam/Gl8zkpJhpEMc6bQVP0yAHgdVqTzRRRLhn60bbi5Sra43ljs1QY6XaxhJiIygZ6AeQrAyKrvhwHM6H2AiPgBfBfA/6mU+qmx5RHRdtVKhtllt8BqEWM1zNnmA2aPc3sML7kxtKRxSUb5OmaYiYjMoCdgPgHgkIiMiYgDwKMAntBz88r13wbwF0qpv25+mUS03SwmsgCAQBMBs4igw2nTnWFWSiGZLTZdkuF1lEtAtnpZxmy0PLQk0GBoiWaw041wIotsYWv/uYiItrqGAbNSqgDg4wCeAvA6gMeVUuMi8mkReQgAROReEZkC8AEAfy4i45WX/zKA+wE8JiJnKv+7sy1/EiLaUhZTeYgAAY/xgBlAJWDO67o2ky+hqBQ6XE0GzJVAe6u3ltNayund2KiVbizEsu1cFhHRjqfrt4tS6kkAT6459slVX59AuVRj7eu+BuBrLa6RiLahxWQWXW47rBbjXSuA8sY/veOqbwwtsTb1LI+WYd7iw0vmomnd9cvAza3lRro97VoWEdGOx0l/RNQWzU7503Q47bpLMpodi63xOrZHhnlmOYMhnfXLwOqAma3liIha0dxvFyKiBiKJHHqaGFqi0WqYlVINSxBamfIH3Mgw681ob4ZSZWhJrQzzF770FcyFozcdyysBcAB/8Z1/wqmnzG1/PxDsxMc+8pip9yQi2qoYMBNRWywmczjQ29H06ztcNhRLCpl8CW5H/VKLRIsBs81qgdNm2dJdMsLJ8tCSWmOx58JRHHnn+9cdd/39OByDR3DkjiFT13P+mW+bej8ioq2MJRlEu1w6V8Rv/OVJnLy6aOp9F5O5pqb8aToMDC/RrvE4ms8BeBzWLd0lY3bZWEs5jd9lRzStb/MkERFVx4CZaJcbn4niqfF5/PpXTuDCfNyUe5ZKCkupXFM9mDUdBoaXJLMFeBzWpjcYAuX656SBQSl6LBUdpg0O0fopG9n0BwCdbjtiGQbMREStYMBMtMtdDiUBlMd3fvjLL5qyQWw5nUdJNTflT6OVV+jNMDdbjqHxmjweO5Et4MnYMH7/u6+Zcj9tyl+tkoxaOt3MMBMRtYoBM9EudymcgMNqwdf/zZsQzxTw2JdPtBxgtTIWW6P1VE7oyI4msoWmO2RoPA6rqV0ynjm/gAIseHU62vhiHWajGThsFsN/p51uOxKZAgqlkinrICLajRgwE+1yl0NJ7Ovx4PbhTvz5v7oHl8MJ/MZfnmxpOpwZAbPHYYVAf0lGyxlmE0sylpI5vHBlETaUcC2SQtyEkgijQ0s0nW47FIC4gTHj9eQKDLyJaPdhwEy0y10OJbC/1wsAeOvBIP7okTvw08uL+O3Hz0Ip1dQ9F5PlyXKtBMwWEXicNiR0tHozoyTD47AiX1SmBIT/9Po8BMC9njAA4PXZ1mvD56IZ9PuNlWMAgN9drgWPmVCWEU3n8Z+/+xrOTprboo6IaKtjwEy0ixWKJVxfTGEseKP92y/etQe/9Z5D+O7Lszg311ygF6lkmFvpwwwAPqetYXa2UCwhky+1XJKhDS9ptbXcbDSNM5PLePOBHgzby/Xhr820XpYxF8sYrl8GbgTMZtQxX19MoVBSeObCApp8L0VEtC0xYCbaxaaW0sgX1UqGWfNztw0AuLEh0KjFRDlgDnjtLa2vp8OBcOVetSQrG/VaL8mojMducePfP47Pw2m34B2He+GWIoIdDrw2G2vpnkopzNUZWlJPp6uSYTahJGNmubzxcD6WxUyBo7aJaPdgwEy0i10OJwAAB9YEzKPBcjB0pXLeqEgyB5/TBqet/sCRRvp8TiwmsygUa5dJaBno1ksyWh+PfSWcxPn5ON5xqBcehw0iwK2D/pYD5qVUHrlCCQNNlGS47BbYrWJKScbMchq9Pid8LhvGM10t34+IaLtgwEy0i2kZ5P3BmyfyeRw2DHa6ms8wtzi0RNPnd6GkgFAiW/OahXj5XLDF53m0DHOT47GVUnhqfA5+lw1vPhBcOX50yI8Lcwnk6wT9jcw22VIOAETElOElSinMLKexN+DBm/f3YLbgwestvhEgItouGDAT7WKXQkkEPHYEqmzO29/rxeVwCwFzCxv+NP2+coCoBcXVzEUzsFkEPR2t1Ut7W8wwvz4bx/XFFN59Sz8cths/Wo8O+pErljCx0Fy2HgDmY+WhJc1s+gPKdcytDi+JZQpI5ooY6nLhvrFu2FDCf//nKy3dk4hou2DATLSLXQknMBb0Vj03FvTicijRVKeMSLK1KX+aYIcDFgEWYrWn5c3HMujzO1ua8gcA7kobu2STGeZT15fQ6bbjnn2Bm47fNuQHALw203w2VpvyZ3QstqbTbW+5JEOrX97T5YbHYcNBZwxPnJ1eCeaJiHYyBsxEu9jlUBL7ezuqnhsLdiCWKWApZTzQWjIpw2yzWtDtdTbMMDdT27uWRQRuh7XpLhmhRBZ7utzrAvexYAdcdktLdczz0Qws0nzZid9lQyxTaLpNIABML6chAAYqQfutzmUUSgpf/cnVpu9JRLRdMGAm2qXimTwW4tl1HTI0+yuZZ6Mb/5RSWEzmqpZ5NKPP58R8rHrAnMgWEM8WTAmYgXJZRrKJLhklpbCYyCFYpSzEahHcMuBvOcPc53PBZm3uR7bfbUexpJr6s2m0DX9auYnfWsDPHR3A/3zhesut+IiItjoGzES71JVw9Q1/Gq1Uw+jGv0S2gFyxZEpJBgD0+2t3ytDKAQaaLFVYy+O0ItXEtL/lVB5FpWpmgI8O+TE+E206wzsXy6C/iQ1/Gr+r9eElM8tpDHXd/Pf8v94/hmg6j78+OdX0fYmItgMGzES7lBYIr20ppxkOuGG3iuGNfzfGYre2CU+jdcqo1o95LqoFzOZlmJvpwxxOaJ06qv+Zjw76EcsUMF2pAzZqLprBYAtZ9E5t2l+TG//imTximcK6gPmefd24a28XvvTjKyiWOMmEiHYuBsxEu9TlUAIWAfb2VB9AYbNasLfbgysGM8w3pvyZV5IBAPPx9ZvL5qIZeJ22lnswazwOK5JNZJi1gLmnToYZaH7jX7NDSzStTvvTNh0Oda1fw//yxn24vpjC+SanQhIRbQcMmIl2qcvhJIYDnrrDRcaCHSulG3ppU/7M2PQHAL0dzpqdMuZirWVe1/I6bUjmjG+OCyeycNosNQP3Wwf8sAia2viXzBYQzxRaCpg7nDYIgFi6uVpjrUPGUJXSl8P9PgDA5FKq6fUREW11DJiJdqlyh4zq5Ria/b1eXIkkUTLwcfuNkgxzAuZanTJKSmG+xczrWh6HFSUFZAvGhoxEKhv+RKq3tnM7rBgLejHeRIZ5TqvTbuGNgdUi8LlsTZdkTC+n0eN1wGVf/+ZqOFAOoqeWmis3ISLaDhgwE+1CpZLClXCy5oY/zVjQi1yhhJmo/mBopSTDhEl/mmqdMiKJHAolZVqHDKCcYQZguCwjnMg2bPl2dKizqZIMs+q0/S30Yq624U/T5bHD67BiihlmItrBGDAT7UJzsQzS+WLDDHMznTIWk1m47BZ4HObUFQPVO2VomddWukes5XVUxmMb2PiXL5awnMrX3PCnOTrox/RyGlGDfa1XAuYW3xg0Ox47nStiKZWvGTCLCIYDHmaYiWhH0xUwi8gDInJeRCZE5BNVzt8vIqdEpCAij6w592ERuVj534fNWjgRNU8LgPfXmPKnudGL2UjAnEePSR0yNNU6ZcxFy4M0tE2BZvA0MR57MZmDQu0OGZqVjX8G65hXSjJazjA3V5KhfbpQbcOfZqTbzYCZiHa0hgGziFgBfB7AgwCOAviQiBxdc9l1AI8B+Pqa13YD+BSANwK4D8CnRCQAItpU2jCSWlP+NL0+JzqcNoMBc9a0+mVNtU4Zc7Esgj4n7E0O86jmRkmG/gxzo5ZymqODTQbM0Qy6PPaq9cNGdLrsyORLyBmsz6634U8zHPBgajHV0iRBIqKtTM9vmvsATCilLiulcgC+AeDh1Rcopa4qpV4GsPYn8c8B+L5SalEptQTg+wAeMGHdRNSCS6EkvA4r+v31gzwRwVjQa6gXs5lT/jS9HU4Ibu6UMRdNm1q/DJQ3/QHGapi1rHejmu1enxN9PifGZ6KG1jRr0uhvf5O9mKeX0+hy21feTFQzHHAjni003YWDiGir0xMw7wEwuer7qcoxPXS9VkQ+KiInReRkKBTSeWsiatblcBJjvd6aXR1WGwt6DY3HjiRzpvVg1tisFvR0OFY6ZWTz5bpaMztkAIDLboXbbsViav2QlFrCiSw6nDZdGeCjQ8ZHZJvVCaTZXsz1NvxptE4ZbC1HRDuVnoC52m9UvZ+76XqtUuqLSqnjSqnjvb29Om9NRM26HEpgrEGHDM1Y0IuppTSyhcZlCkopRBI500syAKDP51rplDFvQqu1Wno6HCu9pPWI6OiQoTk66MfEQkLX36XGtAxzE+OxM/kiwolc3fploFySAbC1HBHtXHoC5ikAI6u+HwYwo/P+rbyWiNogky9iejndcMOfZn+vF0oB1yKNs4cL8SzS+SL21Zge2IrVnTJmTdoIV02P14FwMtv4wopwpQezHkeH/CiUFC7O68vY5wolRJJZkzLM5ZKKWEZ/2cSNCX/1M8wjKwGz+Rnm2Wgaf/zU+Zs6pBARbTQ9AfMJAIdEZExEHAAeBfCEzvs/BeBnRSRQ2ez3s5VjRLRJrkaSUAoNW8ppjLSW0wLBg336stdG9PludMqYi2bgtFnQVSkzMFNPhxPRVF5XgJbJF5HIFnQHzLcNdQLQPyJ7IZ6BUuZk0p02K1x2i6EM88qGvwYBs99tg89pa0uG+esvXMfnfjiBF68smn5vIiK9GgbMSqkCgI+jHOi+DuBxpdS4iHxaRB4CABG5V0SmAHwAwJ+LyHjltYsAfh/loPsEgE9XjhHRJrlSCXwPNOiQoRkz0Fru4kIcAHCoz9fk6mrr89/olDEXK5cp6KnBNqrH64DCjYmF9dzokKGvJGNftwcuuwXn5+O6rp83OZNutBfzzHIaPqdtpZyjFhHBnoC7LRnm5ybCAIAfXeT+FiLaPLomCyilngTw5Jpjn1z19QmUyy2qvfbLAL7cwhqJyERax4sxnSUZPpcdvT6nro1/EwsJdLrtugNII1Z3ypiPZXDHcJfpzwButIeLJHPoa5DZvdEhQ1+G2WIRHOzrwAWdAfOsSVP+NH633VCXjJlo4w1/mvLwEnPhUZflAAAgAElEQVQD5ngmj7NT5a4iPzofwn988FZT709EpBcn/RHtMpdCCfT7nXXbhK1V7pShJ8OcwKG+jrZkfrVOGRfmE8jkS22pXwaw0uEjkmhcxxxOZCGAoU2Oh/t8umuYtSl/g359QWsjnS7947ELxRJC8SwGdf49DwfKw0vM7MX84pVFFEsK9x/uxbm5+E1tBYmINhIDZqJd5nIoif06O2Ro9usMmCcWEjjUb379sqbP58J0pa62HR0yAMDjtMFttyKisySjy2M3NDzlUL8Pc7GMrtKIuWgGLrtlZcNeq/xuGxLZAoqlxkFtKJFFSekfPT7S7UEiW8CywdHf9Tw3EYHTZsG//ZlDAIBnL4ZNuzcRkREMmIl2mSuVHsxGjAW9CCdydYO8SCKLxWQOB9tQv6zpWzVopb9NATNQbi0X0dFaLmKgQ4bmcOUNxcRC47KMuVgGg51u0zL2frcdJQUkdAxmMdq6T+vFbObGv59cCuP4aAB3Dnch2OHEjy6wjpmINgcDZqJdJJ7JI5rOY2+3sbZvejb+TSy0r0OGpt9XDt4CJoyKrqfH60CkQWs5pRTCiazu+mXN4f7yG4oLOsoy5qKZhtMYjTDSi3kumoVVRPcbghsBszl1zOFEFufm4njLgSAsFsH9h4P48cWQruw4EZHZzPmcj4i2Ba2cYU+NjVxf+NJXMBdeP7p5uWgHsA9//D++iQPO6oHe+awfQB/+7puP42mLvl6/L505iyPvfL+ua4EbGeZ2lWNoejqceHkqikKxBFuNcotEtoBsoWR4g+OeLjfcdquujX9zsQzuHe02dP96Og2Mx56PZdDrc8Jq0ZfdNnt4yU8uRQAAbz0YBAC843AvvnVqGq9OR3HHSHs2fBIR1cKAmWgXmVosBzNaNnCtuXC0agBbKJXwxHfGYR95A44c7a/62gtnZ+C4voS73vUvdJcQPPv8izpXXhbscMJhs2DYYIbcqJXWcqkc+nzVg3OtQ4bRkgyLRXCov6Phxr9SSWEhljW19EQbj60nwzwfy2CvgQE0nW47fC6baRnmn0yE4XPZcPuecu/qtx0MQgT40YUQA2Yi2nAsySDaRVYyzDUC5lpsFgsCXsdK3+FqQvEs+nzOtnTI0NitFvzWew7hbZWsY7toZRb16pgjKz2YjZdMHOrzNcwwL6ZyyBVLurtU6OFxWGEVQTRd/xOATL6I5XTecCZ/JODBpEkZ5ucuhfGm/T0rGe6eDieODXXiWdYxE9EmYMBMtItML6fhsFkQ9BoP8oId9QPmhXgGfT7z6m1rCXgchrpSNCOotZar0ykjnMjCahF0eYxPGzzc34GFeBbROh0ltJZyZmaYLSLwuW0NSzK0DX9Gnz1s0vCSycUUJhfTeOuBnpuOv+NwL05PLhvqJU1EZAaWZBDtIlNLKQx3uWHRWZe6Wm+HE5dDyap1vZl8EbFMoWb5wnbjdpTHSNfrxRxO5NDtdcBSJ6P+0qnT+NRn/nTd8am8B8AQ/sNnv4x+W/XewpO58jV/952/xfPfbdwTWm89uF9HL+b5WPl5xgNmD348EYZSqqVPGrTpfm9d80nC/Yd78bkfTuAnE2E8cGyw6fsTERnFgJloF5leShsux9Ac6O3Ac5ciuBpJreuEsRAvB1i9G5Bh3ghS6Q7RKMPcqBwjmc1XDWL7Ujn84KnzcB64D0fGeqq8Eli+EgHOzOD2t753pfa4Hr314J1uO2aj9csm5mIZOGwWw9nz4YAbqVwRS6m8oWEuaz13KYI+n3Pdv2d37e1Ch9OGH10IMWAmog3FgJloG7gwH8eB3g7dHQtqmV5O4+iQv6nX7q88//xcbH3AXPkIfyNKMjZKt9eBycXq5QUlpbCYzOHIQHM9p7vcdjhsFizEameOo+k8LAJ0uMz9Me132XBuLl83Czwfy6Df5zScPb+e8wIYxH/6ky8jaGucFa9GKeD70VEM2dP43T/8s5XjA8FOfOwjj+EtB3rw7IXWs9hEREYwYCbawlK5Aj75nXH8zUtT+INfuh0fum9v0/dK54oIJ3I1W8o14rBZsD/oxYX5BH5+zbmFeBY2iyDQQlZxqwl2OPFKjdZy0VQehZJqasMfUM5g9/mcmI/XHvUcSxfgc9nrBq3N8LvtyBcVMvkS3I71vayVUpiPZXB0sP4bq2rZc380jR8+PQH/rW/FkUp3C6Pmohlknr6Iu47dgiP73rJy/Pwz3wYAvONIL/7xtXlcCiXb2vObiGg1bvoj2qIuzsfx8OeewzdPTcFhs+DElcWW7tdsh4zVDvf7EKpM9FstFM+it0FGcrtZ3VpurXALHTI0/T5X3QxzLJ2H3+TsMrCqtVyNjXOJbAGpXLGpzYYBT/kN05KOseK1XAqV2+0d6K0eDN9/qBcAOPWPiDYUA2aiLehbp6bw0Oeew2Iyh7/49ftw/6FenJlcbumeWvcCbcBEM45UptSdX9MSbSGe2TH1yxqttdxildZy85Wa7R6DQ0tW6/M7y8FpjTHV0UxeV+2yUZ0Npv3NaSOxm2hn57Jb4bZbsVTlTYZel0IJ9Hgd6PJU/7sd6fZgf9DL9nJEtKEYMBNtMf/lydfx24+fxe3DnXjyt96Otx/qxV17u3A5nKzbhqyRRlP+9OjpcKDb68CFuRsBc65QwlIqv2M6ZGh6KuUl4SrZ0vGZKHp9TviczWeAtQyuFnyvFUvnVybzmUkLwqM1AuZmO2RoAh47lpv897RYUrgSTtbMLmvefKAHp64tQSmOySaijcGAmWgLKZYUvvKTq3jf7QP4+r9540rQcsdwebLZ2anms8zTS2nYLNJSX18RwZF+Hy6HE8gXSwDK5RjAztrwB5SHfFRrLbeUyuFaJIU7R7pa2nSm/X1pPY9Xy+SLyBZK8LvaEDBXyjxqlWTMRzPwOm3oaPLNQJfHUbWMRY/5WAbZQgljvd66140FvYhnCzWDfiIiszFgJtpCJhdTyBVKeOfhvps2mr1hpLyB6mwLZRlTS2kMdrla7rRxuN+HfLGcCQTK5RjAzguYRQQ93vWt5V6u/DPQ3sQ0q9Nth9NmWfn7W00rl2hHhtlmtcDjsCJWY9rffDyDfn/z/yy7vQ4sp3JNZX+19oSNJgxqo92nTJoqSETUCANmoi1kYqGy4WnN7n+/y44Dvd6W6pinl9MtlWNo9vd6YbPISh3zQjwLi9yo+d1Jejoc6zLMZ6aWsbfb01KfYWBVp4wqG/9imXIw244aZqAciFfLMJcqHTKMjsRerctT7sKRzBUNvzYUz0JwoxymFq0O34ypgkREejBgJtpCJiodAqq1y7pzJICzU8tN121OLaVa2vCnsVstONDbsVLHvBAvD/BoNXO9FfV4nVhO5VEolctP5qIZzMeyuGOkteyypt/vWulhvVq0jRlmoPwGrFo5w1Iyh3xRtVS200qnjFAii26vY10bv7WYYSaijcaAmWgLmVhIoNfnrBoo3TnSiXAi11SQkCuUsBDPmpJhBoDD/R2IJHMIJ7II7cAOGZpgR7m13FKyHFyemVyGRYDbm+wxvFaf34VkrojEmk4Zl0MJWATwtaGtHFDOXFcLmLV66lYyzCsBcxN1zOF44+mJQPmNRIfTxoCZiDYMA2aiLWRiIYGDNToE3DkSANDcxr/ZaBpK3cjMterIQHmoxWszMUQSuR3XIUOjlQZEElmUlMLLU8s41OdrekPcWv2VNxqrs8zjM1GcnlzG2w/1wt4g09qsoS4XUrkixmeiNx2fi7W+gTNQGae9ZLBTRkkphBNZXW++RATDATdLMohowzBgJtoilFK4tJCoOb3syIAPDpsFZ64bD5i1TFwrQ0tW6/Y6EOxw4qeXI1Ao9xTeibS67Eiy3BljOZ3HHSPmZJeBcoYZuNFaLpbO49unpzHU5cJ7bu0z7TlrHd/XjcFOF544O4NM/kat8Xwsg4DHDqd9/QRAvZx2KzwO472YlyvTE/V+WjEc8DDDTEQbhgEz0RaxEM8ini3UDJgdNguODfmbyjBPVwKL4a7Wa5g1R/o7sFz5WH+ndcjQaK3lwokszk4uw24V3NpgZLQRfpcNLrsFC7EMSkrhm6emkC+W8MvHR2CztO/Hs9UieP9de5DIFPC98bmV4/OxTEv1y5qAp9wpwwitPWGvzs2jwwE3JhdT7MVMRBtC109kEXlARM6LyISIfKLKeaeI/FXl/AsiMlo5bheRr4rIKyLyuoj8R3OXT7RzXJyvveFPc8dIF16Zjq70QNZrajkNizQ3va2WwwPlqX+C1kZEb2Vaa7mFeBavTEdx66AfTlvz2ddq9+/zuTAfy+KnlyO4uJDA+24f3JASl+GAB2850IMXryziajiJQrGEcCLbUv2ypstjX6n71mtl3LjuDLMbyVyx6SEpRERGNAyYRcQK4PMAHgRwFMCHROTomss+AmBJKXUQwGcBfKZy/AMAnEqp2wHcA+A3tGCaiG42sVDuOnGoTsB850gXMvkSLqwZTd3I1FIK/X4XHDbzspZjPV7YrYJur6NttbZbQU+HA1fCSaTzRdxpUneM1fr9Tswsp/G9V+dwy4AP9412m/6MWn7maD+6PHZ8+/Q05mIZlFTzE/5W6/Y4sJTKoWQg+xuKZ+G2W+F16HtDcqO1HMsyiKj99PyWuw/AhFLqslIqB+AbAB5ec83DAL5a+fpvALxHyiOwFACviNgAuAHkAMRMWTnRDjMRSsDnstWt4dQCNqP9mKeX0qZt+NPYrBa8eX/QtBZrW1WPt/zPw+Ow4lCfz/T79/lcyBVLcNqt+KW7h1uaHmiU02bFL965B6FEFt8+PQ0A6DfhU4g+vxOFksKigdZyocqGP71//hut5bjxj4jaT0/AvAfA5KrvpyrHql6jlCoAiALoQTl4TgKYBXAdwB8rpRZbXDPRjjRR2fBXL2DY2+1BwGM3PPFvasmcoSVrPXBsAD9za7/p991KejrKnTJu39PZll7T+3o8sIrgkbv3mNZ9w4jD/T7cMdyJ2WgGFim30muVVlJSrcd0LaG4vg4ZmhFmmIloA+kJmKv9hlj7OVuta+4DUAQwBGAMwL8Tkf3rHiDyURE5KSInQ6GQjiUR7TwTC8maLeU0IoI7RroMZZgLxRLmYhnTOmTsNnsDHrjsFhxvU6nEcMCDT/3C0ZVWfZvh598wBLfdil6f05TNhtomUK37RyPpSi9qvRv+AMDvtsHntDHDTEQbQs9PxikAI6u+HwYwU+uaSvlFJ4BFAL8C4HtKqbxSagHAcwCOr32AUuqLSqnjSqnjvb29xv8URNtcNJVHOJGtu+FPc+dIFy4uJBCvMtq4mvl4FsWSMmXK324U9DnxyX9xW1sy9JpGk+3arcNpw79+6yh+6a5hU+7ntFvR5bbrzjBrG/6MZJhFBMPdbC1HRBtDz0/pEwAOiciYiDgAPArgiTXXPAHgw5WvHwHwtCr3+rkO4N1S5gXwJgDnzFk60c4xESpv4tMTMN8x0gWlgFemow2vBYCpxXIGrp0BH21/wwEPRrrNe1PV5y93F9HDaEs5zXDAjUlmmIloAzQMmCs1yR8H8BSA1wE8rpQaF5FPi8hDlcu+BKBHRCYA/DYArfXc5wF0AHgV5cD7fyilXjb5z0C07U0sNG4pp7lz2NjGv+nlSg9mlmTQBur3uRCKZ3V1ygglsrCKIOA1Vj9dnvaXZi9mImo7XTtMlFJPAnhyzbFPrvo6g3ILubWvS1Q7TkQ3m1hIwGGz6CqbCHgd2Nfj0b3xTxtaMsQMM22gPr+r3CkjkWvYWzkUz6Lb66i7qfKlU6fxqc/86U3HXst0IpXrxSf+78/BZTHWm7yegWAnPvaRx0y7HxFtfxu/JZuI1plYSGB/0Ku7C8OdI1346eWIrmunltIIdjjhamHcMZFRNzb+ZRoHzInGHTKS2TyOvPP9Nx0rzkRx4oXr6LnrvabW6J9/5tum3YuIdoadO22AaBu5WGkpp9cdw12Yj2UxG2284Wl62fwezESN9PnLAXCjOuZiJQttZMOfpstTLuFY4rQ/ImozBsxEmyydK2J6OW1oKMY9+wIAgBNXlxpeO7WUYks52nBOmxVdHjvmG3TKWErmUFTK8IY/AAhUAubllP4BKUREzWDATLTJLoUSUErfhj/NbUN+dDhteKFBWUappDCznMEw65dpE/T7XFiI1c8whyot5RqVbVTjdljhsluwxICZiNqMATPRJrsU0t8hQ2OzWnDPvgBeuFJ/cGY4kUWuWGJJBm2KPr8ToUS5D3gtzbaU0wQ8DiwlWZJBRO3FTX9Em2xiIQGLAKPB6puWvvClr2AuvL7ncjzThYl0EL/zB5+D21Ks+tqFggvAMJ75wfcx8WzjfrUvnTm7bmMVUbP6fK5yjXKydo1yKJFFh9MGt6O5TakBj2Nl8AkRUbswYCbaZBMLCezr8cJpqx4wzIWjVYNYdySJU89ehvXIO3BkT2fV12amloETkzj2xneg3+9quJZnn3/R2OKJ6uivbPybj2VqB8zxxh0y6gl47Li4EIdSCiL6uswQERnFkgyiTTaxkMCBXv3lGJo9AQ/sVsGVcLLmNcvJcm1nl8fe9PqImqUFwvU6ZYTiWQSbLMcAyp0y8kWFZK76pyxERGZgwEy0iQrFEq5GkobqlzVWi2BftxdX6wTMS+k83HZrzew1UTs5bVYEPHYsxKt3ykhmC0jniy1mmNkpg4jajwEz0Sa6tphCvqiaCpgBYDToxVwsg1S2UPV8KJ5FwMvsMm2evjqdMlrd8Adg5d9v9mImonZiwEy0iSYWjHfIWG0s6AUAXI2szzIvJnO4Gk7i1gF/8wskalF/nU4ZWks5MzLMS0lmmImofRgwE20iLWA+0Ott6vUjATdslup1zC9eWYQIcHy0u6U1ErVC65QRSa7PMofiWdgs0lKNvctuhdtuZS9mImorBsxEm2hiIYHBThd8ruYCBpvVgpFuz7qAuVAs4aVri7hlwI9ON0syaPOsjMiuUpahbfiztNjdIuCxM2AmorZiwEy0iSYWEk2XY2jGgl7MRjNIr+oSMD4bQzJXxBvHmF2mzdXnK7czrLbxL5zINjXhb60uj8PUGuZsyYJrVcqciGj3YsBMtElKJYVLoeZayq02FvRCATf9gn/xyiK6vQ4caDEYJ2qVw2ZBwGPH/JoM8+uzMUSSOYyYMIUy4LFjOZWDUrUnCupVUgo/SAzikf/2fN0JhUS0uzBgJtoks7EMUrliyxnmvd0eWFfVMS/EMrgSTuK+0e6WP+omMkO/33VThjmeyeObp6Yw2OnCm/f3tHz/gNe8Xsynry8hVHQjFM/i7NRyy/cjop2BATPRJmm1Q4bGbrVgOODGlUqG+YWri7BaBHfvC7S8RiIz9PmcCMdzKJYUlFL45qkp5Aol/PLxEdisrf8aMqtTRjpXxD+8OoceawYWAX54bqHltRHRzsCAmWiTmBUwA+WyjJnlNOKZPE5fX8KxIT86nJx8T1tDn9+Foip3ynj+cgQX5hN48NiArnHteqwEzC1u/PvH1+aQzhXxFs8C7tkXwNMMmImoggEz0SaZWEigy2NHj9fR8r3Ggl6UFPD3L88iky/hvrHWP+YmMkt/ZePfK9NRfO/VORzp9+FNJpRiaLS2dK1s/JteTuPFK4t404EedNtyeNctfRifiWE+Vn1KIRHtLgyYiTbJpYUEDvZ2QEyoM97X7YVFygFJn8+J0R6PCSskMkevzwkB8IPXF+C0WfBLd+8x5d97Tau9mEtK4Ykz0/A6bfiZW/oBAO++pQ8AyzKIqIwBM9EmmQi13lJO47BZsKer3G3gjWPdpgYjRK1y2CwIVD5J+Zd3Dzfdd7yebq8Di4nmAuZT15YwuZTGA8cG4HZYAQBH+n3Y0+VmWQYRAQBY5EhkkFKq5YA0kshiMZkzLWAGgMMDPoQSWdw5ws1+tPW8aX8PCsUSbhlsz6j2Ab8L5+Zihv/7TOUK+N74HPb1eHDXSNfKcRHBu27pxbdOTSNbKMJps7Zj2US0TTDDTGRAvljC+/7sx/jdJ8Zbuo+ZG/407zzch3/33iMrGTKireRtB4N455G+tt1/sMuFZK6IeLZg6HUvXVtCKlfEQ3cMrQu0331LH1K5Il64vGjmUoloG2LATGTA1356Da/PxvBXJyYRzzS/wWgiZH7AbLUIvOyMQbvUYGe5JGl22dgmvSvhJIIdzpXXr/bm/UE4bRaWZRCRvoBZRB4QkfMiMiEin6hy3ikif1U5/4KIjK469wYReV5ExkXkFRExp48Q0QZbTuXwJ/90EWNBL9L5Ip44O9P0vSYWEnDbrRiq8kuaiIwb7Cz/apmNpnW/pqQUrkaSGAtW3yTrdljxlgM9+OH5BVOmCBLR9tUwYBYRK4DPA3gQwFEAHxKRo2su+wiAJaXUQQCfBfCZymttAL4G4H9TSt0G4J0Amk/LEW2iP/vBBOKZPP7fX70btwz48I0XJ5u+18RCAgf6vLBYuDmPyAwuuxUBjx2zUf0Z5rloBpl8CaM93prXvPuWPlyLpHA5nKx5DRHtfHoyzPcBmFBKXVZK5QB8A8DDa655GMBXK1//DYD3SLkY7GcBvKyUOgsASqmIUqr12aVEG+xyKIG/eP4qPnjvCG4d9OPRe0fwynQUr05Hm7qf1lKOiMwz2Ok2lGHWxsmPBWsHzO9iezkigr6AeQ+A1am0qcqxqtcopQoAogB6ABwGoETkKRE5JSK/0/qSiTbeH/zDOThtFvzv7z0MAPjFu/bAYbPgr04YzzInswXMRDOm1i8TUXnjXySRQ7agLy9zNZJEwGNHl6f28KDhgAdH+n2sYyba5fQEzNU+M15bzFXrGhuAtwH41cr/v19E3rPuASIfFZGTInIyFArpWBLRxvnJpTC+/9o8fvNdB9FXmVjW5XHgfccG8LdnppHOGfvQ5FIbNvwRETDU6YZCudSiEaUUroSTdbPLmnfd0ocXryy2tNGXiLY3PQHzFICRVd8PA1i722nlmkrdcieAxcrxHymlwkqpFIAnAdy99gFKqS8qpY4rpY739vYa/1MQtUmxpPCf//517Oly4yNvG7vp3KP37UU8U8CTr8waumc7WsoR0eqNf40D5oV4FqlcsW79subdt/ShUFL454vhltdIRNuTnoD5BIBDIjImIg4AjwJ4Ys01TwD4cOXrRwA8rcpbip8C8AYR8VQC6XcAeM2cpRO137dOTeG12Rh+54EjcNlv7m/8xrFujAW9+MaJ64buObGQgM0i2KfjFzUR6dfptsNtt+qqY74aaVy/rLl7bxc63XY8c55lGUS7VcOAuVKT/HGUg9/XATyulBoXkU+LyEOVy74EoEdEJgD8NoBPVF67BOC/ohx0nwFwSin1XfP/GETt8bdnpnGwrwMP3TG07pyI4IP3juDE1SVMLMR13/PiQgL7ejywW9kGnchMIoLBLpeuDPOVcBJ+lw3d3tr1yxqb1YI7R7rw6nTMjGUS0Tak6ze2UupJpdRhpdQBpdT/VTn2SaXUE5WvM0qpDyilDiql7lNKXV712q8ppW5TSh1TSnHTH20bSimMz8Rwz95AzVG7//LuYdgsYmjz36WFBA71+cxaJhGtMtTpxlw0g2Kpdt9kpRSuhpMYDXp1j9E+MuDDRCiBQrFk1lKJaBthiouohploBsupPI7t8de8ptfnxHuP9uObp6Z17czPFUq4tphi/TJRmwx2ulAoKYQT2ZrXLCZziGUKusoxNEf6fcgVSiulHES0uzBgJqphvNJj+ehQZ93rPnjvCBaTOfzTa43rG69GkiiWFANmojZZGZFdpyxD67+sZ8Of5shA+VOhc3P6y6+IaOdgwExUw/hMDCLArYP1yyfefqgXvT4n/k7HqGx2yCBqr16fE1aL1N34dzWShMdhRZ/Pqfu+B/s6YLUILjBgJtqVGDAT1TA+E8P+oBceh63udVaL4H3HBvDD8wtIZgt1r9UC5v297JBB1A5Wi6Df72yYYR4zUL8MlEdvj/Z4mGEm2qXqRwJEu9j4TBT3jnbruvZ9tw/iq89fw9PnFvALVTpqaCYWEtjT5W4YhBNR8wY73Tg3G4NSal1QvJzKYSmVx1sPBmu+/qVTp/Gpz/zpuuOFRD+ejzjxqc88Z+p6B4Kd+NhHHjP1nkRkLv7WJqpiMZnDbDSD24Zqb/hb7fhoN3p9Tjz5ymzDgJnlGETtNdjpwkvXlhDPFOB32286p6d+OZnN48g737/u+NS5eTz9+gLG3vYwHDbzPqA9/8y3TbsXEbUHSzKIqhifKW/4O7an/oY/jdUiePDYAJ4+V7sso1RSuBxmwEzUbjc2/q2vY74aScJlt2CgMhXQiAG/CwrAfKxxn2ci2lkYMBNVMT5THlCgN8MMlMsysoUSnj5XvVvG9HIamXyJATNRm9UbkX0lnMRojxcWA/XLmgF/+b4MmIl2HwbMRFWMz8Swp8uNLk/jKWCae1eVZVTDDhlEG8Nlt6Lb68DMmoA5HM8inMgZaie3WsDrgN0qmGPATLTrMGAmqmJ8JoqjBrLLwI2yjB+eX0Aqt74s48WriwCAg70MmInabbDThdnlGyUZl8MJ/LdnL8Fltxj65Gg1iwj6/S5mmIl2IW76I1ojmS3gSjiJh2ps3vvCl76CuXC06rn5vAuZ/DA+9pmvYtSRWDkeKjjxD/FhjNoT+JPPfcHQel46c7bqBiQiqm2w043xmRiy+SLOTC3j787OoNvrxK+9aR96OvT3X16r3+fCuXm2liPabRgwE61xbi4GpYDbakz4mwtHawawh5TCc/9wDuHOw/i5N+4DAKRzRXznhxfR5QH+1bveCLfDamg9zz7/orE/ABFhqFLH/D9fuI6JUAKH+zvw6L174bIb++9vrf5OF166voREtoAOJ3+FEu0WLMkgWuPV6fKGv2N7jH9saxHBsT1+XJiPI1coQSmFb52eQiydx6P37jUcLBNRcwa7yp0yJkIJ3H8oiF9782jLwTJwY+PfXPjdYJMAACAASURBVJ3BKES08/DtMdEa4zNRdHsdK78YjTq2pxM/vbyIc3MxpHJFjM/E8MBtAxjp9pi8UiKqxe+y4e0HgxgKuHHHcJdp9+33l8s55mMZbuAl2kUYMBOtMT4Tw21DfkNjc1cb7fGiw2nDP18MYz6WweH+DrztUO2pYkRkPhHBg7cPmn5fn8sOr8PKThlEuwxLMohWyRVKuDAfN9whYzWLCG4b8mN6OQ23w4pH7hlpqucrEW1N/Z3slEG02zBgJlrl4kIc+aKqueFPr3v2BeCyW/DLx0e4MYhoh+n3u7AQy6Kk1GYvhYg2CH+TE63SzIS/aoYDHvynnz/adFkHEW1dA34XcsUSlpK5llrUEdH2wQwz0SqvzcTgdVgx1uQksNUYLBPtTByRTbT7MGAmWmV8JopbB/2wWBjsElF1fZVOGdz4R7R7MGAmqiiVFF6rdMggIqrFabOi2+vAXCy72Ushog3CgJmo4mokiWSu2PKGPyLa+fp9TsxzeAnRrsGAmahC2/DXSks5Itod+jtdiCSzyBdLm70UItoADJiJKl6ZjsJhs+Bwv2+zl0JEW9yA34WSAkJxlmUQ7Qa6AmYReUBEzovIhIh8osp5p4j8VeX8CyIyuub8XhFJiMi/N2fZROY7c30Ztw354bDxfSQR1dfPThlEu0rDyEBErAA+D+BBAEcBfEhEjq657CMAlpRSBwF8FsBn1pz/LIB/aH25RO2RL5bw8vQy7hzp2uylENE2EOxwwmmz4GoktdlLIaINoCeVdh+ACaXUZaVUDsA3ADy85pqHAXy18vXfAHiPVJrQisgvArgMYNycJROZ7/xcHJl8CXftDWz2UohoG7BaBAf7OnBhPg7FiX9EO56egHkPgMlV309VjlW9RilVABAF0CMiXgD/AcDv1XuAiHxURE6KyMlQKKR37USmOTO5DAC4ixlmItLpSL8P0XSe/ZiJdgE9AXO1CQ5r307Xuub3AHxWKZWo9wCl1BeVUseVUsd7e3t1LInIXKevL6PH68BwwL3ZSyGibULbIHx+Lt7U67OFIi6FEjibDuDXv3IC33xpyszlEZGJbDqumQIwsur7YQAzNa6ZEhEbgE4AiwDeCOAREflDAF0ASiKSUUp9ruWVE5nozOQS7trbxXHWRKSb323HUKcL5+fjeOeRPt2ve302hh+cm8dcNIOSAoBueC9HMD4TxcN3DsFm5cZjoq1Gz3+VJwAcEpExEXEAeBTAE2uueQLAhytfPwLgaVX2dqXUqFJqFMCfAPgvDJZpq4mm87gUSnLDHxEZdmTAh+uRFNK5oq7rs4UivnlqCtl8Ce843IvH3jKKD3VewX/94J2Yj2Xxw/MsSyTaihoGzJWa5I8DeArA6wAeV0qNi8inReShymVfQrlmeQLAbwNY13qOaKs6W6lfvnOEG/6IyJgj/T4oABcW9JVl/PRSBKlcEb98fATvPTqAw/0+OCwlvPuWPvT5nPjGi9fbu2AiaoqekgwopZ4E8OSaY59c9XUGwAca3ON3m1gfUdudmVyGCPCGEY7EJiJjhrs98DisuDAXxx3D9T+lyuSLePZiGEf6fRjp9tx0zm614APHh/GFZy5hNprGYCf3UxBtJSyUol3v9PUlHOztgN9l3+ylENE2YxHB4X4fzs/HUWrQXu75yxGk80W859bq9c6P3rsXJQU8foKb/4i2GgbMtKsppXBmkgNLiKh5R/p9SOWKmF5K17wmky/ixxfDuGXAh+GAp+o1I90evP1QEI+fnESxxN7ORFsJA2ba1a4vprCUynNgCRE17VB/BwTAuTrt5X5yKVzOLt/SX/dej967F9PLaTx7kZv/iLYSBsy0q52+rm34Y4aZiJrjcdiwt9uDC/PVA+Z0rogfT4Rx64APexr0en/v0X70eB3c/Ee0xTBgpl3tzOQy3HYrDvd3bPZSiGgbOzLgw/RyGrFMft25n1wKI5Mv4T231s8uA4DDZsEj9wzjn15fwAInCBJtGQyYaVc7PbmMNwx3clAAEbXkyEB56t/FNVnmdK6I5y6FcXTQj6EufZ0vPnjvCIolhb/m5L//v707j466vvc//nzPkkw2spMAAcISFit7RNSqVG2rtkrdbW/R3tqq7dX21nOs9nduW+vptdcu12uv1lZri1WvG2ql7gtF3IEQtohhhyRAIEAC2Sczn98fMypLEgYMmQl5Pc6ZMzPf72e+855zPnx55/P9fN8fkYShLEH6rdZgiA+3NjB5mKZjiMhnUzggwICA75N5zI1tHSyo3MHv56+lNRipsxyrkfnpzBiZwxOLqwjr5j+RhBBTHWaR49GH2/YSDDmmaP6yiHxGZsbYwgxWVDfwdFk1y6vr6Qg7RuWncfGUId2OLpctLefnd959wDZ/ezpbmgq57o4HGOzvuvrG0SjMy+R713yrR48pcrxTwix92rPl1ZRvqeeWc8eRlnxk3fnjG/5UIUNEesK4wgEs3rSHFTX1TB2ezSkjcykYEDjs55ragoydedEB20aGwnzw4moa8ifwhclDejTOygXP9ujxRPoDJczSZy2vqufHc1cQDDkWbdzNA1eVHrJ6VneWVdUzKDMQ039oIiKHM64wg6tPKWZYTiopSd7PdCy/18Po/HTWbN+Hcw4z66EoReRoaA6z9El7W4Pc+Fg5AzMC/O/Xp7C1voUL73mbd9fXxXyMZVV7VE5ORHrMx9MyPmuy/LGxhRnUtwSp3dfWI8cTkaOnhFn6HOcc/++ZldTUt3D3lZO5YNJgnrvh8+SmJzP7wUU89O4m3GGWqK1rbKNqd4sSZhFJWGMKIpU31nSzIIqI9A4lzNLnPLG4iudXbOOmL46htDgHgBF5aTz7/VOZOSafn8+r4I4XV3d7jHvmrwPglFG5xzxeEZGjkZniZ1BmoNsVBEWkdyhhlj5lTe0+bvtHBaeNzuX6M0cdsC8j4Of+q0qZPWM4D7y1kYff39zpMV5YsY05727i26eNYGKRRphFJHGNLchgy+4mWtpD8Q5FpF9Twix9RmswxA3/t5T0ZB93XTEZr+fQm2C8HuO2Cz/HF8bmc9u8Ct5ee+Cc5g07G7nl6RVMGZbFreeN663QRUSOytjCDMIO1u7QKLNIPClhlj7jr+9sYk1tI7+7fDIDM7qubOH1GL//+hRG56fz/UfLWL+zEYisuPX9R5fi9xr3fmMqST51fxFJbENzUknxe1lTq4RZJJ6UMUif4JzjySVVTC/O4cwx+YdtnxHw8+erS/F7PXznoSXUN7fzs+dWUVm7j7uumBzzErUiIvHkMaOkIJ3K2kbCh7mZWUSOHSXM0ieUbd7DxromLi0tivkzQ3NS+dPsadTsaeHCe97hqbJqbvzCaGaOjX2JWhGReBtXmEFTWwdb63t2xT8RiZ0SZukTnlpSTWqSl69MGHREnystzuG/LpnAlt3NnDY6lx+eM+YYRSgicmyUDMzAgEpVyxCJG630Jwmvub2D51ds5SsTBh3x8tcAF08tYnhuGmMLMzq9UVBEJJGlJfsYmpNKZe0+zh5fEO9wRPolJcyS8F5cuZ2m9hCXlQ7tdP99D85he11Dr8VTtmw5Y2de1GvfJyIypiCD11fXsq81SEbAH+9wRPodJcyS8J5aUkVxbionFWd3un97XUOvJrAL31vUa98lIgKR8nKvr65lbW0jU4d3fi4UkWNHc5gloW3e1cQHG3dz6bQizDSdQkT6p8GZATICPipVXk4kLpQwS0KbW1aNGVwyLfbqGCIixxszY0xBBmt37CMUVnk5kd4WU8JsZueaWaWZrTOzWzvZn2xmT0T3f2BmxdHtXzSzMjNbGX0+q2fDl+NZKOx4uqya00vyGZSpuski0r+NK8ygNRjWIiYicXDYhNnMvMC9wHnACcDXzeyEg5pdA+xxzo0G7gLujG6vAy5wzk0ArgYe7qnA5fj37vo6tja0cplGl0VEGFc4gKxUPwsqd+C0iIlIr4plhHk6sM45t8E51w48Dsw6qM0s4KHo67nA2WZmzrly59zW6PYKIGBmyT0RuBz/nlpSTWaKny+eoDJKIiJej3HmmHyq9rSwbkdjvMMR6VdiSZiHAFX7va+Obuu0jXOuA2gAcg9qcwlQ7pxrO/gLzOxaM1tiZkt27twZa+xyHGtoDvJyxXZmTR5MwO+NdzgiIglh2rBsMlP8zP9Io8wivSmWhLmz0gQH/yvtto2ZfY7INI3rOvsC59z9zrlS51xpfn5+DCFJogr30M0of1iwjmAozNenD+uR44mIHA98Xg9nlOSxeXczG+qa4h2OSL8RS8JcDey/YkQRsLWrNmbmAzKB3dH3RcCzwFXOufWfNWBJXH9YsI5xP3uZb89ZzDNLq9nXGjyq42zZ1cxf39nEJVOLGD9oQA9HKSLSt5UW55AR8DH/ox3xDkWk34hl4ZLFQImZjQBqgCuBbxzUZh6Rm/reAy4F5jvnnJllAS8AP3HOvdNzYUui+fNbG/j1y5WUDs/mo217mf/RDpJ8HmaOyecbJw9j5tiBMR/rVy+txusxbv7y2GMYsYhI3+T3ejijJJ8XVm5jY10TI/LS4h2SyHHvsCPM0TnJNwCvAKuBJ51zFWZ2u5ldGG32IJBrZuuAm4CPS8/dAIwGfmpmy6KP2DMn6RMefn8zv3xhNedPKOTxa2fw9i1n8fT3TuFfTh7G8up6vvXXxTyxeEtMx/pgwy5eWrWd688cRcGAwDGOXESkbzqpOIe0ZB//rDz8KLNzjo11TWze1aQaziJHKaalsZ1zLwIvHrTtZ/u9bgUu6+RzvwR++RljlAT25JIqfvr3VZwzfiD/c8UUfN7I32DThucwbXgOt5w7jmsfLuPWZ1bi9Xi4tJsSceGw45cvrGZQZoBrzxjZWz9BRKTPSfJ5OH10Hi9XbGfL7maG5aR22m5DXSOvVdSyeXczAMk+D/k2iOFvb+T0kjxKCjJ6M2yRPiumhFmkM88tq+GWp1dwekke93xjKkm+Qy9YBPxe7p89je88tISb5y7H7zVmTT64yErEM+U1rKxp4K4rJpGSpMoYIiLdOXlkDgvX7uSlVds4fXQ+Wal+slL9pPi91NS38NqHtazd0ciAgI9ZkweTluRj3c5GVm9u5fbnPwTg5i+P5d++MDrOv0Qk8SlhlqOysrqBm55czvTiHO6fXdpt6beA38sDV5Xy7TmL+dETy/CYccGkwQe0aW7v4DevfMSkokxmTeo8oRYRkU8l+7ycM76Aecu3snnX5k+2J/k8tHeESU3yct6JhcwYmYs/evXvxCGZjK9fxHe++11+9dJqfvtqJROGZHLGGFWoEumOEmY5YuGw46fPrSI7NYkHri49ZDT4vgfnsL2u4ZDPjXDGeu9gfvDYUv74zHzSPB0EPCGSLUR1MI3atiymuvX84jdlRxRP2bLljJ150Wf6TSIifdGMkbmcOCST+uZ26puD1De3s6clyICAn5NH5HQ5mDE0J5XfXjaJ9Tua+OHj5fzjxs9TlN35tA4RUcIsR+GpsiqWVdXz35dPYkDAf8j+7XUNXSawJcEQjy7aQsWOQ0t3TxiSyenTJxxxPAvfW3TEnxEROV6kJ/tIT/ZRlH1kn0tN8vHH2dO48H/f5vuPLuXJ607RQlEiXVDCLEekoTnInS9XclJxNhdNOfKpE8l+L98+bQShsKMlGKKprYPm9hAt7SFG5qs0kohIbxqRl8bvLp/EtQ+X8Yt/VPCriyfGOySRhKSEWY7I716rpL65nV9ceDJmnS3wGBuvxz4ZFRERkd5TtrScn9959wHbJgRyeGwRbF61hJLkfT36fYV5mXzvmm/16DFFepuyFYlZxdYGHnl/M7NnDOeEwVqBT0SkL2pqCx4yba7EOVre2cSiXUbpjM9TmNlzdfArFzzbY8cSiZdYlsYWwTnHz56rIDs1iZu+pBX4RESOJx4zLj9pKAG/lyeXVNERCsc7JJGEooRZYvLM0hrKNu/hlvPGkZly6I1+IiLSt6Un+7h46hC2723l9dW18Q5HJKEoYZbDqt7TzB0vrmby0Cwundr1Sn0iItK3jSscwEnFOby1to6NdU3xDkckYShhlm7tbQ3y7TmLaQ+F+e1lE/F4jv5GPxERSXznTygkOy2JuWVVtAZD8Q5HJCEoYZYuBUNhvv/IUjbsbOJP35zG6IEZ8Q5JRESOsWSfl8unFVHfHOSFFdviHY5IQlDCLJ1yzvEfz67i7XV1/OriCZw6Oi/eIYmISC8ZlpvGmWPzKduyh4qth67cKtLfKGGWTv1hwXqeWFLFjWeN5rLSofEOR0REetlZ4wYyOCvA00urWVPbs7WZRfoa1WE+jlXtbqahJUhbR4i2jjDtHWHMjPGFGQwccGiNTeccm3Y180rFdn7zSiWzJg/mpi+OiUPkIiISbz6Ph29MH84j72/moXc3cda4gXxh3EA8n2HRKpG+SgnzccY5x4I1O7n/zQ28t2FXl+0GZiQzsSiTCUOySA/4KNu8m0Ub91DX2AbAqaNy+fWlEz/Tan4iItK35aQlcf2Zo3huWQ1vfLSDqj3NXD5tKKlapVX6GfX440R7R5jnltXwwFsbWFPbSOGAAD8+dyyj89NJ9ntJ8npI8nkIhsJ8uHUvq2oaWFHTwBsf7cA5GJKVwukleZxUnMP0EdmMyk9XsiwiIiT5PFw6rYhhuak8v2Ib9/xzHV/6XAFpyT4CPi/Jfg/JPi+twRB7W4I0RB+NbR1kpyYRDqbQ0BwkM1U1/KXvUsLcx4XCjmfLa/jvVyvZ2tDKuMIMfnfZJC6YNJgkX+dT1GeMzP3kdWNbB01tHRR0MkVDREQEwMw4eUQuQ7JS+L9FW3hySXX37YFkv4fWYBgYwqu3v8qwnFSmDMvi6lOLmTosu1fiFukpSpj7sLfW7uSOFz9i9ba9TCzK5I6LJ3DmmPxOR4bve3AO2+t6507nsmXLGTvzol75LhER6T1F2an86Jwx1DW20RYM09YRorUjTGswRMDnJTPFT2aKn4wUHz6Ph6a2DhYtfJ0pnz+Lipq9vLlmJ88t28rpJXnceFYJ00fkxPsnicRECXMvCYUde5rb2dPUzu7oo6ElSEFmgNH56QzJSolpUZDWYIjyLfXc9+Z6Fq7ZSVF2CndfOZkLJg7u9vPb6xp6LYld+N6iXvkeERHpfX6vh0GZKTG1TUv2sW3luwz2t5AHnJ9kVLpMFq/r4PK1dRT6mpkY2EOhr4WemAVYmJfJ96751mc/kMhBlDAfQx2hMO+u38XzK7by8qrt7G3t6LJtwO9hZF46I/PTGJQZoGBAgIEDAhRkJNMRdnywcTcfbNhFeVU97R1hMlP8/MdXxjP7lOEk+7y9+KtERERi19QWPGDA5kTggo4wizftZuGanbzamMqgzACnjsxjUlEmPu/RV7ytXPBsD0QsciglzD3MOcfSLfU8W17NSyu3s6upnfRkH186oYBJQ7PISUv65JER8LGtoZV1Oxo/eayobuC1D2tp6wgfcFyPwecGZ3LVjOHMGJnLySNzyAjoBgoREel7knweThudx/QROSyvquftdXU8vbSaVyq2c/LIHCYVZZGdmoQ3hiuvzjnaOsI0t4fYE0pib2uQAfr/UXqYEuYe0tjWwd/La3jk/c18tH0fAb+Hc8YX8NWJg5k5Np+A/8BR4M7mFBdHHy4d2p2HZuejJezFYeT7WklqDhOsgLcq4K0jjE/zikVEJNH4vR5Ki3OYNjybdTsbeWddHW+s3sEbq3fgsUhZu9y0ZPLSkwBobg/R3B6iJRiiub2D5vYQrcEQYffxEYcx77ZXyQj4GJKVQlF2KqPy0ygtzuGk4myyUpPi9lulb4spYTazc4G7AS/wZ+fcfx20Pxn4GzAN2AVc4ZzbFN33E+AaIAT8wDn3So9FH2cdoTDlVfX8vbyGv5fX0NQe4oRBA7jjognMmjyYtG7qVPbmnGLQvGIREUlcZkbJwAxKBmZQt6+NzbubqGtsp66xjV2N7Wyoa8TMSE3ykur3kpLkZVBmCin7vU9N8vHBy3MpGD6axrCPxl1+ynb6mL86iT8t3ABAtreNgb4W8r2t5PraGOAJEsMgdpc0Z7r/OGzCbGZe4F7gi0A1sNjM5jnnPtyv2TXAHufcaDO7ErgTuMLMTgCuBD4HDAZeN7MxzrlQT/+Q3tLQHOTNtTuZv7qWBWt2Ut8cJNnn4asTB/PNGcOYPDRL9YtFRESOUl5GMnkZyUf12aW7N3DJdd89YFswFKZ6TwubdjWxqa6JjbubqWyLTHv0e43CAQEGZ6WQmeIn4PeS4vcS8HsJ+CNzqcMOws5FHuHIFJDIe3ivYhHDV24jNclLerKPtGQfaUm+SKWQgC+mm/mlb4hlhHk6sM45twHAzB4HZgH7J8yzgNuir+cC91gka5wFPO6cawM2mtm66PHe65nwe04wFKaprYN9rR2f1Cbe2xpky65mNtY1saGuiY11TdTUt+Bc5DLRWeMGcva4Ak4fk6f5UiIiIgnI7/UwIi+NEXlpMDZStWpnYxvb6lvYWt9CTX0ry6rqD7l3KDaFLHx0aad7PAZZqUlkp/rJTo3ct5Sa7CM9KZJYpyZ5P6kM4hw4HC46tcRFt33M6wGvx4PXDK8HPB6LvjY8Zvi8kdd+rwe/1/B5PJ++jj77vR68Hose1+33vZ9+l3PuwPe4j5vi8Rg+j33y7PVEvse733vvwfu8++0z69N/QMSSMA8BqvZ7Xw2c3FUb51yHmTUAudHt7x/02SFHHe0xNPM3C6ipb+l0X3qyjxF5aUwdls1l04by+ZI8Jg/NiulmBBEREUkcXk9kVLlwQIAp+y2gEgxF6km3BEO0BiOvjUiiaAYeIgmfxyJTSDwGL/3tXsaPH08HHoLO6HAegs5Du/PQ5ry0Br201Xuo3uMlGN0XdJ5IOyI5xMGZxIHvHWCRJPaQln2PGfg81umV+F9fMpGvTUnIFBEAc/v/CdNZA7PLgC87574TfT8bmO6cu3G/NhXRNtXR9+uJjCTfDrznnHskuv1B4EXn3NMHfce1wLXRt2OByh74bYkuD6iLdxDSJ6ivSCzUTyRW6isSq/7QV4Y75/IP1yiWEeZqYOh+74uArV20qTYzH5AJ7I7xszjn7gfujyGW44aZLXHOlcY7Dkl86isSC/UTiZX6isRKfeVTsVQHXwyUmNkIM0sichPfvIPazAOujr6+FJjvIkPX84ArzSzZzEYAJYDKNYiIiIhIn3HYEebonOQbgFeIlJX7i3OuwsxuB5Y45+YBDwIPR2/q200kqSba7kkiNwh2AP/WlytkiIiIiEj/c9g5zHJsmNm10akoIt1SX5FYqJ9IrNRXJFbqK59SwiwiIiIi0o1Y5jCLiIiIiPRbSphFRERERLqhhLkXmNmPzKzCzFaZ2WNmFohWHfnAzNaa2RPRCiTSz3XRV+aY2UYzWxZ9TI53nBJ/ZvbDaD+pMLN/j27LMbPXoueV18ws+3DHkeNbF/3kNjOr2e+ccn6845TeZ2Z/MbMdZrZqv22dnkMs4vdmts7MVpjZ1PhFHh9KmI8xMxsC/AAodc6dSKTSyJXAncBdzrkSYA9wTfyilETQTV8BuNk5Nzn6WBa3ICUhmNmJwHeJLBA1CfiqmZUAtwJvRM8rb0TfSz/VTT+ByP8/H59TXoxbkBJPc4BzD9rW1TnkPCKlgUuILDR3Xy/FmDCUMPcOH5ASXdQlFdgGnAXMje5/CPhanGKTxHJwXzlkoR8RYDzwvnOu2TnXAbwJXATMInI+AZ1XpOt+IoJzbiGRUsD76+ocMgv4m4t4H8gys0G9E2liUMJ8jDnnaoDfAluIJMoNQBlQHz2BQWRFxMRdQF16RWd9xTn3anT3f0Yvg91lZslxC1ISxSrgDDPLNbNU4Hwiq6oWOOe2AUSfB8YxRom/rvoJwA3Rc8pfNHVH9tPVOWQIULVfu36XtyhhPsaiJ6JZwAhgMJBG5NLGwVTfr5/rrK+Y2TeBnwDjgJOAHOCWuAUpCcE5t5rItK7XgJeB5UQWhxL5RDf95D5gFDCZyB/nv4tXjNJnWCfb+lXeooT52DsH2Oic2+mcCwLPAKcSuZzx8UqLRejSu3TRV5xz26KXwdqAvxKZjyj9nHPuQefcVOfcGUQuq64Faj++TBp93hHPGCX+Ousnzrla51zIORcGHkDnFPlUV+eQaj69OgH9MG9RwnzsbQFmmFmqmRlwNpGlwv8JXBptczXwXJzik8TRWV9Zvd/Jy4jMJ1vVzTGknzCzgdHnYcDFwGPAPCLnE9B5Rei8nxw09/QidE6RT3V1DpkHXBWtljGDyJTBbfEIMF600l8vMLNfAFcQuRRWDnyHyNyfx4lcYi8HvhkdQZR+rIu+8hKQT+SS2DLgeudcY9yClIRgZm8BuUAQuMk594aZ5QJPAsOI/AF2mXPu4Jt6pB/pop88TGQ6hgM2Adf1t+RHwMweA2YCeUAt8HPg73RyDokO2NxDpKpGM/Cvzrkl8Yg7XpQwi4iIiIh0Q1MyRERERES6oYRZRERERKQbSphFRERERLqhhFlEREREpBtKmEVEREREuqGEWUSkDzOzP5vZCYdp87XDtRERka6prJyIyHHOzOYAzzvn5sY7FhGRvkgjzCIiCcTMis3sIzN7yMxWmNnc6OqPZ5tZuZmtNLO/mFlytP0CMyuNvm40s/80s+Vm9r6ZFZjZqcCFwG/MbJmZjTKzH5jZh9HjPx7P3ysi0hcoYRYRSTxjgfudcxOBvcBNwBzgCufcBMAHfK+Tz6UB7zvnJgELge86594lsqztzc65yc659cCtwJTo8a8/5r9GRKSPU8IsIpJ4qpxz70RfPwKcDWx0zq2JbnsIOKOTz7UDz0dflwHFXRx/BfComX2TyDLsIiLSDSXMIiKJ52hvLgm6T29MCREZie7MV4B7gWlAmZl11U5ERFDCLCKSiIaZ2SnR118HXgeKzWx0dNts4M0jON4+IAPAs+Cd8AAAAJ5JREFUzDzAUOfcP4EfA1lAeo9ELSJynFLCLCKSeFYDV5vZCiAHuAv4V+ApM1sJhIE/HsHxHgduNrNyoAR4JHqccuAu51x9j0YvInKcUVk5EZEEYmbFRErAnRjnUEREJEojzCIiIiIi3dAIs4iIiIhINzTCLCIiIiLSDSXMIiIiIiLdUMIsIiIiItINJcwiIiIiIt1QwiwiIiIi0o3/D4+VUEsdfTv+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 5))\n",
    "sns.distplot(wine_base[\"points\"],hist=True,bins = 20,hist_kws={'edgecolor':'black'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wine2 = pd.DataFrame()\n",
    "wine2 = wine_base\n",
    "nbins  = 3\n",
    "labels=[\"low\",\"medium\",\"high\"]\n",
    "g,b = pd.qcut(wine2[\"points\"],nbins,labels=labels,retbins=True)   #uses quartiles and statistic stuff\n",
    "g.tolist()\n",
    "wine2[\"category\"] = g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wine2.drop(\"description\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parallel coordinates would be nice\n",
    "\n",
    "low = wine2[wine2[\"category\"] == \"low\"]\n",
    "medium = wine2[wine2[\"category\"] == \"medium\"]\n",
    "high = wine2[wine2[\"category\"] == \"high\"]\n",
    "\n",
    "wine3 = pd.DataFrame()\n",
    "features = [\"category\",'vintage', 'country', 'points', 'price', 'province','region_1', 'taster_name', 'variety', 'winery','similarityTop3WinesByVariety', 'word_count']\n",
    "for feat in features:\n",
    "    wine3[feat] = wine2[feat]\n",
    "fig, ax = plt.subplots(figsize = (25, 10))\n",
    "parallel_coordinates(wine3, 'category', colormap=plt.get_cmap(\"Set2\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE NUMBER OF BINS = classes to be predicted (must be executed so that Y is the same for every execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80.,  87.,  90., 100.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = wine_base['points'].copy()\n",
    "#DECIDE NUMBER OF BINS \n",
    "#nbins  = 4\n",
    "#labels=[\"low\",\"medium\",\"high\",\"very_high\"]\n",
    "#nbins = 5\n",
    "#labels=[\"very_low\", \"low\", \"medium\",\"high\",\"very_high\"]\n",
    "#bin identici \n",
    "#Y,bins = pd.cut(Y,nbins,labels=labels,retbins=True,include_lowest=True,right=True)\n",
    "#quartile\n",
    "nbins  = 3\n",
    "labels=[\"low\",\"medium\",\"high\"]\n",
    "Y,bins = pd.qcut(Y,nbins,labels=labels,retbins=True)   #uses quartiles and statistic stuff\n",
    "values = Y.tolist()  \n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'seaborn' from 'E:\\\\Anaconda\\\\lib\\\\site-packages\\\\seaborn\\\\__init__.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the binning result\n",
    "fig, ax = plt.subplots(figsize = (12, 5))\n",
    "for i in range(1,len(bins)-1):\n",
    "\n",
    "    if i == 1:\n",
    "        a = wine_base[wine_base[\"points\"] <= bins[i]]\n",
    "        n =  bins[i]-80\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "        g =+n\n",
    "    if i == len(bins)-1:\n",
    "        a = wine_base[wine_base[\"points\"] > bins[i]]\n",
    "        n = 100 - bins[i]\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "        g =+ n\n",
    "    else:\n",
    "        n = bins[i+1] - bins[i]\n",
    "        g =+n\n",
    "        a = wine_base[(wine_base[\"points\"] > bins[i]) & (wine_base[\"points\"] <= bins[i+1])]\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "ax.set(xticks=wine_base[\"points\"].unique())\n",
    "print(g)\n",
    "sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic = [\"price\",'vintage', 'country', 'province', 'region_1', 'taster_name', 'variety','winery']\n",
    "word = [\"word_count\"]\n",
    "tfGroup = ['tf_grouped_1','tf_grouped_2', 'tf_grouped_3']\n",
    "tfIdfGroup = ['tfIdf_grouped_1', 'tfIdf_grouped_2', 'tfIdf_grouped_3']\n",
    "tfFull = ['tf_fullData_1', 'tf_fullData_2', 'tf_fullData_3',]\n",
    "tfIdfFull = ['tfIdf_fullData_1', 'tfIdf_fullData_2', 'tfIdf_fullData_3']\n",
    "#weather = ['pr_5', 'pr_6', 'pr_7', 'pr_8', 'pr_9', 'tas_5', 'tas_6', 'tas_7', 'tas_8', 'tas_9']# don't really care bcs 0 improvements\n",
    "word2vec = ['similarityTop3WinesByVariety']\n",
    "features = basic + word + tfGroup + word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUMMY CLASSIFIER = BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = wine_base.loc[:,features]\n",
    "test_size = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "classifier = DummyClassifier(\"stratified\")\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)  \n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFIER WITHOUT SPARSE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decTree(features, depth, data):\n",
    "    X = data.loc[:,features]\n",
    "    test_size = 0.30\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "    classifier = DecisionTreeClassifier(max_depth=depth)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred = classifier.predict(X_test)  \n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "\n",
    "    #get feature importances\n",
    "    lista = []\n",
    "    for name, importance in zip(features, classifier.feature_importances_):\n",
    "        lista.append([name, importance])\n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(y_test, y_pred,labels=labels)\n",
    "    print(classification_report(y_test, y_pred, target_names=labels))\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"price\",\"vintage\"] #basic + word2vec + word_count...\n",
    "depth = 4\n",
    "clf = decTree(features,depth,wine_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show me the tree\n",
    "\n",
    "##### Graphviz sucks, you need to check if it's installed and it may give you problems anyway, the code below fixed it for me\"\n",
    "#### be sure that you have the package installed\n",
    "import os\n",
    "import sys\n",
    "def conda_fix(graph):\n",
    "        path = os.path.join(sys.base_exec_prefix, \"Library\", \"bin\", \"graphviz\")\n",
    "        paths = (\"dot\", \"twopi\", \"neato\", \"circo\", \"fdp\")\n",
    "        paths = {p: os.path.join(path, \"{}.exe\".format(p)) for p in paths}\n",
    "        graph.set_graphviz_executables(paths)\n",
    "import pydotplus \n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=features,  \n",
    "                         class_names=labels,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "conda_fix(graph)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier using sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparseMatrixRep(features,depth,data,test_size):\n",
    "    X = data.loc[:,features+[\"description\"]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    #compute countvectorizer\n",
    "    vect = CountVectorizer(min_df=5)\n",
    "    vect.fit(X_train['description'])\n",
    "    print(\"vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "    X_train_vectored_cv = vect.transform(X_train['description'])\n",
    "    X_train_final = X_train_vectored_cv\n",
    "    for feature in features:\n",
    "        X_train_final = hstack((X_train_final,np.array(X_train[feature])[:,None]))\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth=depth)\n",
    "    clf.fit(X_train_final, y_train)\n",
    "    \n",
    "    y_train_pred = clf.predict(X_train_final)\n",
    "    X_test_final = vect.transform(X_test['description'])\n",
    "    for feature in features:\n",
    "        X_test_final = hstack((X_test_final,np.array(X_test[feature])[:,None]))\n",
    "\n",
    "    y_test_pred = clf.predict(X_test_final)\n",
    "    print(classification_report(y_test, y_test_pred, target_names=labels))\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the input and compute\n",
    "\n",
    "features = [\"price\"] #basic #+ word + tfGroup + word2vec\n",
    "depth = 3\n",
    "test_size = 0.30\n",
    "clf = sparseMatrixRep(features,depth,wine_base,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show me the tree\n",
    "##### Graphviz sucks, you need to check if it's installed and it may give you problems anyway, the code below fixed it for me\"\n",
    "#### be sure that you have the package installed\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pydotplus \n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "\n",
    "def conda_fix(graph):\n",
    "    path = os.path.join(sys.base_exec_prefix, \"Library\", \"bin\", \"graphviz\")\n",
    "    paths = (\"dot\", \"twopi\", \"neato\", \"circo\", \"fdp\")\n",
    "    paths = {p: os.path.join(path, \"{}.exe\".format(p)) for p in paths}\n",
    "    graph.set_graphviz_executables(paths)\n",
    "    \n",
    "dot_data = tree.export_graphviz(clf, out_file=None,   \n",
    "                             class_names=labels,  \n",
    "                             filled=True, rounded=True,  \n",
    "                             special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "conda_fix(graph)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with combinations and get results dataframe (no countvect working on this as of now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with every test combination you put\n",
    "def testToDataFrame(algorithm,combination,Y,allfeats,dataset):\n",
    "    test_size = 0.30 \n",
    "    cols = [\"algorithm\",\"input\",\"precision\",\"accuracy\",\"depth\"]\n",
    "    for lab in labels:\n",
    "        cols.append(lab +\"_prec\")\n",
    "        cols.append(lab +\"_recall\")\n",
    "        cols.append(lab +\"_f1\")\n",
    "        cols.append(lab +\"_support\")\n",
    "    for el in allfeats: #controlla che allfeats vada bene, amgari fotte con l'ordine\n",
    "        cols.append(\"feat_\"+el)\n",
    "    results = pd.DataFrame()\n",
    "    row = 0\n",
    "    comb = 0\n",
    "    for el in combination[\"args\"]: \n",
    "        for depth in combination[\"depth\"]:\n",
    "            row = row + 1\n",
    "            X = dataset.loc[:,el]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "            if algorithm == \"decTree\":\n",
    "                classifier = DecisionTreeClassifier(max_depth=depth)\n",
    "            else:\n",
    "                classifier = RandomForestClassifier(max_depth=depth,n_estimators = estimators)\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_pred = classifier.predict(X_test)  \n",
    "            acc = accuracy_score(y_test,y_pred)\n",
    "            weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")        \n",
    "            data = [algorithm,el,weightedPrec,acc,depth]\n",
    "            precision,recall,fscore,support = precision_recall_fscore_support(y_test, y_pred)\n",
    "            for i in range(0,len(labels)):\n",
    "                data.append(precision[i])\n",
    "                data.append(recall[i])\n",
    "                data.append(fscore[i])\n",
    "                data.append(support[i])\n",
    "            #for lab in labels:\n",
    "            \n",
    "             #   data.append(rep[lab].precision)     #ORDER IS VERY IMPORTANT\n",
    "              #  data.append(rep[lab].recall)\n",
    "               # data.append(rep[lab].f1-score)\n",
    "                #data.append(rep[lab].support)\n",
    "            temp = {}\n",
    "            c = zip(el,classifier.feature_importances_)\n",
    "            for name,importance in c:\n",
    "                temp[name] = importance\n",
    "            for feat in allfeats:\n",
    "                if feat not in el:\n",
    "                    data.append(100) #100 is an impossible value not to be taken into account\n",
    "                else:\n",
    "                    data.append(temp[feat])\n",
    "            df2 = pd.DataFrame([data],columns=cols)\n",
    "            results = results.append(df2,ignore_index=True)\n",
    "        comb = comb + 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [[\"price\"],[\"price\",\"word_count\"],basic,basic+tfGroup, basic+word2vec,basic+word2vec+tfGroup,word2vec,tfGroup,word2vec+tfGroup]\n",
    "allfeatures = basic + word + word2vec + tfGroup \n",
    "decTreeCombinations = {\"depth\":[2,3,4,5],\"args\":args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = testToDataFrame(\"decTree\",decTreeCombinations,Y,allfeatures,wine_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort_values([\"precision\",'depth'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.iloc[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.iloc[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test stuff based on countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 5, 10, 4, 2, 11, 6, 1, 3, 9, 7, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = wine_base[\"country\"].unique().tolist()\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 4639\n",
      "5 1939\n",
      "10 5510\n",
      "4 17931\n",
      "2 2784\n",
      "11 48572\n",
      "6 16699\n",
      "1 2086\n",
      "3 4046\n",
      "9 1241\n",
      "7 1206\n",
      "0 3380\n"
     ]
    }
   ],
   "source": [
    "for c in countries:\n",
    "    print(c,len(wine_base[wine_base[\"country\"] == c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 5, 10, 4, 2, 11, 6, 1, 3, 9, 7, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = wine_base[\"country\"].unique().tolist()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testByCountry(data,countries):\n",
    "    #for every country, use it as test set\n",
    "    nbins  = 3\n",
    "    labels=[\"low\",\"medium\",\"high\"]\n",
    "    wine2 = pd.DataFrame()\n",
    "    wine2 = data\n",
    "    g,b = pd.qcut(data[\"points\"],nbins,labels=labels,retbins=True)   #uses quartiles and statistic stuff\n",
    "    g.tolist()\n",
    "    wine3 = wine2.drop([\"points\",\"description\"],axis=1)\n",
    "    wine3[\"category\"] = g\n",
    "    df = pd.DataFrame()\n",
    "    for el in countries:\n",
    "        res = applyTest(wine3,el)\n",
    "        df = df.append(res)\n",
    "    return df\n",
    "\n",
    "def applyTest(data,objCountry):\n",
    "    #set many different combinations\n",
    "    args = [[\"price\"],[\"price\",\"word_count\"],basic,basic+tfGroup, basic+word2vec,basic+word2vec+tfGroup,word2vec,tfGroup,word2vec+tfGroup]\n",
    "    allfeatures = basic + word + word2vec + tfGroup \n",
    "    combos = {\"depth\":[2,3,4,5,6],\"args\":args}\n",
    "    #\n",
    "    res = buildCountryResult(data,args,allfeatures,combos,objCountry)\n",
    "    return res\n",
    "\n",
    "def buildCountryResult(data,args,allfeatures,combination,objCountry):\n",
    "    print(type(data))\n",
    "    cols = [\"algorithm\",\"ObjectiveCountry\",\"input\",\"precision\",\"accuracy\",\"f1\",\"depth\"]\n",
    "    algorithm = \"decTree\"\n",
    "    for lab in labels:\n",
    "        cols.append(lab +\"_prec\")\n",
    "        cols.append(lab +\"_recall\")\n",
    "        cols.append(lab +\"_f1\")\n",
    "        cols.append(lab +\"_support\")\n",
    "    for el in allfeatures: #controlla che allfeats vada bene, amgari fotte con l'ordine\n",
    "        cols.append(\"feat_\"+el)\n",
    "    results = pd.DataFrame()\n",
    "    comb = 0\n",
    "    row = 0\n",
    "    for el in combination[\"args\"]: \n",
    "        el = el+[\"country\",\"category\"]\n",
    "        print(\"datalop\",type(data))\n",
    "        X = data[el]\n",
    "        #create test and training sets\n",
    "        X_train = X[X[\"country\"] != objCountry]\n",
    "        y_train = X_train[\"category\"]\n",
    "        X_train.drop([\"country\",\"category\"],axis=1,inplace=True)\n",
    "\n",
    "        X_test = X[X[\"country\"] == objCountry]\n",
    "        y_test = X_test[\"category\"]\n",
    "        X_test.drop([\"country\",\"category\"],axis=1,inplace=True)\n",
    "        for depth in combination[\"depth\"]:\n",
    "                row = row + 1  \n",
    "                #train stuff\n",
    "                classifier = DecisionTreeClassifier(max_depth=depth)\n",
    "                classifier.fit(X_train,y_train)\n",
    "                y_pred = classifier.predict(X_test)  \n",
    "                acc = accuracy_score(y_test,y_pred)#average=\"macro\")\n",
    "                weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "                f1 = f1_score(y_test,y_pred,average=\"weighted\")\n",
    "                rowData = [algorithm,objCountry,el,weightedPrec,acc,f1,depth]\n",
    "                precision,recall,fscore,support = precision_recall_fscore_support(y_test, y_pred)\n",
    "                for i in range(0,len(labels)):\n",
    "                    rowData.append(precision[i])\n",
    "                    rowData.append(recall[i])\n",
    "                    rowData.append(fscore[i])\n",
    "                    rowData.append(support[i])\n",
    "                    temp = {}\n",
    "                c = zip(el,classifier.feature_importances_)\n",
    "                for name,importance in c:\n",
    "                    temp[name] = importance\n",
    "                for feat in allfeatures:\n",
    "                    if feat not in el:\n",
    "                        rowData.append(100) #100 is an impossible value not to be taken into account\n",
    "                    else:\n",
    "                        rowData.append(temp[feat])\n",
    "                df2 = pd.DataFrame([rowData],columns=cols)\n",
    "                results = results.append(df2,ignore_index=True)\n",
    "        comb = comb + 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n",
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalop <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "basic = [\"price\",'vintage', 'province', 'region_1', 'taster_name', 'variety','winery'] #country non deve esserci \n",
    "word = [\"word_count\"]\n",
    "tfGroup = ['tf_grouped_1','tf_grouped_2', 'tf_grouped_3']\n",
    "tfIdfGroup = ['tfIdf_grouped_1', 'tfIdf_grouped_2', 'tfIdf_grouped_3']\n",
    "tfFull = ['tf_fullData_1', 'tf_fullData_2', 'tf_fullData_3',]\n",
    "tfIdfFull = ['tfIdf_fullData_1', 'tfIdf_fullData_2', 'tfIdf_fullData_3']\n",
    "#weather = ['pr_5', 'pr_6', 'pr_7', 'pr_8', 'pr_9', 'tas_5', 'tas_6', 'tas_7', 'tas_8', 'tas_9']# don't really care bcs 0 improvements\n",
    "word2vec = ['similarityTop3WinesByVariety']\n",
    "features = basic + word + tfGroup + word2vec\n",
    "\n",
    "\n",
    "result = testByCountry(wine_base,countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>ObjectiveCountry</th>\n",
       "      <th>input</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>depth</th>\n",
       "      <th>low_prec</th>\n",
       "      <th>low_recall</th>\n",
       "      <th>low_f1</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_province</th>\n",
       "      <th>feat_region_1</th>\n",
       "      <th>feat_taster_name</th>\n",
       "      <th>feat_variety</th>\n",
       "      <th>feat_winery</th>\n",
       "      <th>feat_word_count</th>\n",
       "      <th>feat_similarityTop3WinesByVariety</th>\n",
       "      <th>feat_tf_grouped_1</th>\n",
       "      <th>feat_tf_grouped_2</th>\n",
       "      <th>feat_tf_grouped_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, word_count, country, category]</td>\n",
       "      <td>0.761018</td>\n",
       "      <td>0.728621</td>\n",
       "      <td>0.740264</td>\n",
       "      <td>5</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.674556</td>\n",
       "      <td>0.578680</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.220698</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.759386</td>\n",
       "      <td>0.705635</td>\n",
       "      <td>0.720397</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.759386</td>\n",
       "      <td>0.705635</td>\n",
       "      <td>0.720397</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, word_count, country, category]</td>\n",
       "      <td>0.757136</td>\n",
       "      <td>0.718735</td>\n",
       "      <td>0.732052</td>\n",
       "      <td>4</td>\n",
       "      <td>0.531486</td>\n",
       "      <td>0.624260</td>\n",
       "      <td>0.574150</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.212848</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, word_count, country, category]</td>\n",
       "      <td>0.752856</td>\n",
       "      <td>0.732081</td>\n",
       "      <td>0.739606</td>\n",
       "      <td>6</td>\n",
       "      <td>0.483936</td>\n",
       "      <td>0.713018</td>\n",
       "      <td>0.576555</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.231704</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.751701</td>\n",
       "      <td>0.699456</td>\n",
       "      <td>0.715948</td>\n",
       "      <td>6</td>\n",
       "      <td>0.507109</td>\n",
       "      <td>0.633136</td>\n",
       "      <td>0.563158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022199</td>\n",
       "      <td>0.024663</td>\n",
       "      <td>0.097252</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.751701</td>\n",
       "      <td>0.699456</td>\n",
       "      <td>0.715948</td>\n",
       "      <td>6</td>\n",
       "      <td>0.507109</td>\n",
       "      <td>0.633136</td>\n",
       "      <td>0.563158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017915</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.093846</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.008546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, word_count, country, category]</td>\n",
       "      <td>0.750910</td>\n",
       "      <td>0.710826</td>\n",
       "      <td>0.724421</td>\n",
       "      <td>3</td>\n",
       "      <td>0.458647</td>\n",
       "      <td>0.721893</td>\n",
       "      <td>0.560920</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.160747</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.746141</td>\n",
       "      <td>0.703658</td>\n",
       "      <td>0.716443</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.030755</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.746141</td>\n",
       "      <td>0.703658</td>\n",
       "      <td>0.716443</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.030755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.743812</td>\n",
       "      <td>0.690559</td>\n",
       "      <td>0.707416</td>\n",
       "      <td>5</td>\n",
       "      <td>0.432479</td>\n",
       "      <td>0.748521</td>\n",
       "      <td>0.548212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011277</td>\n",
       "      <td>0.023257</td>\n",
       "      <td>0.080463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.743812</td>\n",
       "      <td>0.690559</td>\n",
       "      <td>0.707416</td>\n",
       "      <td>5</td>\n",
       "      <td>0.432479</td>\n",
       "      <td>0.748521</td>\n",
       "      <td>0.548212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011263</td>\n",
       "      <td>0.021490</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.743010</td>\n",
       "      <td>0.708876</td>\n",
       "      <td>0.720585</td>\n",
       "      <td>6</td>\n",
       "      <td>0.643510</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.682832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006943</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.083260</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.118335</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.741467</td>\n",
       "      <td>0.706509</td>\n",
       "      <td>0.718321</td>\n",
       "      <td>6</td>\n",
       "      <td>0.631206</td>\n",
       "      <td>0.735537</td>\n",
       "      <td>0.679389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.082216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.116774</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.007574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, word_count, country, category]</td>\n",
       "      <td>0.738154</td>\n",
       "      <td>0.685799</td>\n",
       "      <td>0.702064</td>\n",
       "      <td>4</td>\n",
       "      <td>0.676409</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.208156</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.735628</td>\n",
       "      <td>0.644970</td>\n",
       "      <td>0.667010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.707989</td>\n",
       "      <td>0.530992</td>\n",
       "      <td>0.606848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.735628</td>\n",
       "      <td>0.644970</td>\n",
       "      <td>0.667010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.707989</td>\n",
       "      <td>0.530992</td>\n",
       "      <td>0.606848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, word_count, country, category]</td>\n",
       "      <td>0.735563</td>\n",
       "      <td>0.699408</td>\n",
       "      <td>0.711634</td>\n",
       "      <td>5</td>\n",
       "      <td>0.634234</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.677575</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.734350</td>\n",
       "      <td>0.714497</td>\n",
       "      <td>0.722421</td>\n",
       "      <td>5</td>\n",
       "      <td>0.653226</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.661224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.083502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.101612</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.732770</td>\n",
       "      <td>0.709467</td>\n",
       "      <td>0.718516</td>\n",
       "      <td>5</td>\n",
       "      <td>0.653226</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.661224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.083463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.098923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, word_count, country, category]</td>\n",
       "      <td>0.729667</td>\n",
       "      <td>0.711243</td>\n",
       "      <td>0.718133</td>\n",
       "      <td>6</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>0.739669</td>\n",
       "      <td>0.675472</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.224951</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.727089</td>\n",
       "      <td>0.649408</td>\n",
       "      <td>0.669809</td>\n",
       "      <td>3</td>\n",
       "      <td>0.707989</td>\n",
       "      <td>0.530992</td>\n",
       "      <td>0.606848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.030008</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.727089</td>\n",
       "      <td>0.649408</td>\n",
       "      <td>0.669809</td>\n",
       "      <td>3</td>\n",
       "      <td>0.707989</td>\n",
       "      <td>0.530992</td>\n",
       "      <td>0.606848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.030008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.721963</td>\n",
       "      <td>0.733317</td>\n",
       "      <td>0.726335</td>\n",
       "      <td>6</td>\n",
       "      <td>0.562842</td>\n",
       "      <td>0.609467</td>\n",
       "      <td>0.585227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005724</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>0.077431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.115057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.007023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.721026</td>\n",
       "      <td>0.703254</td>\n",
       "      <td>0.707909</td>\n",
       "      <td>4</td>\n",
       "      <td>0.561863</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.659266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.084827</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.721026</td>\n",
       "      <td>0.703254</td>\n",
       "      <td>0.707909</td>\n",
       "      <td>4</td>\n",
       "      <td>0.561863</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.659266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.084827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.719624</td>\n",
       "      <td>0.732328</td>\n",
       "      <td>0.724400</td>\n",
       "      <td>6</td>\n",
       "      <td>0.563187</td>\n",
       "      <td>0.606509</td>\n",
       "      <td>0.584046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.012443</td>\n",
       "      <td>0.078627</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.116650</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.717692</td>\n",
       "      <td>0.726891</td>\n",
       "      <td>0.717972</td>\n",
       "      <td>4</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.721893</td>\n",
       "      <td>0.590085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.087968</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>decTree</td>\n",
       "      <td>3</td>\n",
       "      <td>[price, vintage, province, region_1, taster_na...</td>\n",
       "      <td>0.717692</td>\n",
       "      <td>0.726891</td>\n",
       "      <td>0.717972</td>\n",
       "      <td>4</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.721893</td>\n",
       "      <td>0.590085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.087968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>decTree</td>\n",
       "      <td>0</td>\n",
       "      <td>[price, word_count, country, category]</td>\n",
       "      <td>0.716481</td>\n",
       "      <td>0.669527</td>\n",
       "      <td>0.683655</td>\n",
       "      <td>3</td>\n",
       "      <td>0.555060</td>\n",
       "      <td>0.770661</td>\n",
       "      <td>0.645329</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.156641</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>decTree</td>\n",
       "      <td>2</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.296483</td>\n",
       "      <td>0.268678</td>\n",
       "      <td>0.221781</td>\n",
       "      <td>2</td>\n",
       "      <td>0.608264</td>\n",
       "      <td>0.297735</td>\n",
       "      <td>0.399783</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.716919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>decTree</td>\n",
       "      <td>9</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.293495</td>\n",
       "      <td>0.469782</td>\n",
       "      <td>0.360330</td>\n",
       "      <td>4</td>\n",
       "      <td>0.317518</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.355102</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.252547</td>\n",
       "      <td>0.086869</td>\n",
       "      <td>0.660584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>decTree</td>\n",
       "      <td>9</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.288283</td>\n",
       "      <td>0.454472</td>\n",
       "      <td>0.352772</td>\n",
       "      <td>2</td>\n",
       "      <td>0.277946</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.336380</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.058303</td>\n",
       "      <td>0.110743</td>\n",
       "      <td>0.830954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>decTree</td>\n",
       "      <td>9</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.287753</td>\n",
       "      <td>0.452861</td>\n",
       "      <td>0.351899</td>\n",
       "      <td>3</td>\n",
       "      <td>0.277612</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.337568</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.162240</td>\n",
       "      <td>0.097926</td>\n",
       "      <td>0.739834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decTree</td>\n",
       "      <td>1</td>\n",
       "      <td>[similarityTop3WinesByVariety, country, category]</td>\n",
       "      <td>0.287074</td>\n",
       "      <td>0.387824</td>\n",
       "      <td>0.245239</td>\n",
       "      <td>2</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.090278</td>\n",
       "      <td>0.154303</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>decTree</td>\n",
       "      <td>8</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.423152</td>\n",
       "      <td>0.295410</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363426</td>\n",
       "      <td>0.126613</td>\n",
       "      <td>0.187799</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.729237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>decTree</td>\n",
       "      <td>4</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.275137</td>\n",
       "      <td>0.407228</td>\n",
       "      <td>0.326526</td>\n",
       "      <td>2</td>\n",
       "      <td>0.409787</td>\n",
       "      <td>0.511342</td>\n",
       "      <td>0.454966</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.723602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>decTree</td>\n",
       "      <td>4</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.274930</td>\n",
       "      <td>0.386983</td>\n",
       "      <td>0.289548</td>\n",
       "      <td>2</td>\n",
       "      <td>0.443263</td>\n",
       "      <td>0.263176</td>\n",
       "      <td>0.330265</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.057587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.942413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>decTree</td>\n",
       "      <td>8</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.273342</td>\n",
       "      <td>0.420349</td>\n",
       "      <td>0.290013</td>\n",
       "      <td>2</td>\n",
       "      <td>0.358056</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.171674</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.063424</td>\n",
       "      <td>0.105744</td>\n",
       "      <td>0.830832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decTree</td>\n",
       "      <td>4</td>\n",
       "      <td>[similarityTop3WinesByVariety, country, category]</td>\n",
       "      <td>0.267216</td>\n",
       "      <td>0.382020</td>\n",
       "      <td>0.308981</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>decTree</td>\n",
       "      <td>4</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.265644</td>\n",
       "      <td>0.374324</td>\n",
       "      <td>0.269035</td>\n",
       "      <td>4</td>\n",
       "      <td>0.423466</td>\n",
       "      <td>0.200068</td>\n",
       "      <td>0.271748</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.164255</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.831225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>decTree</td>\n",
       "      <td>6</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.263946</td>\n",
       "      <td>0.422241</td>\n",
       "      <td>0.323321</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333162</td>\n",
       "      <td>0.650841</td>\n",
       "      <td>0.440721</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.758013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>decTree</td>\n",
       "      <td>4</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.261545</td>\n",
       "      <td>0.368412</td>\n",
       "      <td>0.257863</td>\n",
       "      <td>3</td>\n",
       "      <td>0.415301</td>\n",
       "      <td>0.168514</td>\n",
       "      <td>0.239748</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.155963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.844037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decTree</td>\n",
       "      <td>6</td>\n",
       "      <td>[similarityTop3WinesByVariety, country, category]</td>\n",
       "      <td>0.260902</td>\n",
       "      <td>0.404336</td>\n",
       "      <td>0.311904</td>\n",
       "      <td>2</td>\n",
       "      <td>0.319038</td>\n",
       "      <td>0.710123</td>\n",
       "      <td>0.440274</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>decTree</td>\n",
       "      <td>6</td>\n",
       "      <td>[similarityTop3WinesByVariety, country, category]</td>\n",
       "      <td>0.260902</td>\n",
       "      <td>0.404336</td>\n",
       "      <td>0.311904</td>\n",
       "      <td>3</td>\n",
       "      <td>0.319038</td>\n",
       "      <td>0.710123</td>\n",
       "      <td>0.440274</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decTree</td>\n",
       "      <td>9</td>\n",
       "      <td>[similarityTop3WinesByVariety, country, category]</td>\n",
       "      <td>0.252575</td>\n",
       "      <td>0.444803</td>\n",
       "      <td>0.309182</td>\n",
       "      <td>2</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>decTree</td>\n",
       "      <td>7</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.245752</td>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.304912</td>\n",
       "      <td>2</td>\n",
       "      <td>0.287846</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.374480</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.724221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>decTree</td>\n",
       "      <td>1</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.244888</td>\n",
       "      <td>0.387824</td>\n",
       "      <td>0.293063</td>\n",
       "      <td>2</td>\n",
       "      <td>0.348432</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.717126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decTree</td>\n",
       "      <td>5</td>\n",
       "      <td>[similarityTop3WinesByVariety, country, category]</td>\n",
       "      <td>0.243287</td>\n",
       "      <td>0.352759</td>\n",
       "      <td>0.271520</td>\n",
       "      <td>2</td>\n",
       "      <td>0.525721</td>\n",
       "      <td>0.559413</td>\n",
       "      <td>0.542044</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>decTree</td>\n",
       "      <td>11</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.235263</td>\n",
       "      <td>0.375401</td>\n",
       "      <td>0.235125</td>\n",
       "      <td>2</td>\n",
       "      <td>0.305079</td>\n",
       "      <td>0.058913</td>\n",
       "      <td>0.098755</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.717612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>decTree</td>\n",
       "      <td>6</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.234019</td>\n",
       "      <td>0.395712</td>\n",
       "      <td>0.281831</td>\n",
       "      <td>2</td>\n",
       "      <td>0.352197</td>\n",
       "      <td>0.293896</td>\n",
       "      <td>0.320416</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.726824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>decTree</td>\n",
       "      <td>5</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.222038</td>\n",
       "      <td>0.287261</td>\n",
       "      <td>0.222780</td>\n",
       "      <td>3</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.395194</td>\n",
       "      <td>0.436256</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.148244</td>\n",
       "      <td>0.100971</td>\n",
       "      <td>0.750785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>decTree</td>\n",
       "      <td>6</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.220856</td>\n",
       "      <td>0.377747</td>\n",
       "      <td>0.271804</td>\n",
       "      <td>2</td>\n",
       "      <td>0.308435</td>\n",
       "      <td>0.304949</td>\n",
       "      <td>0.306682</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.037349</td>\n",
       "      <td>0.066584</td>\n",
       "      <td>0.896067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>decTree</td>\n",
       "      <td>7</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.218883</td>\n",
       "      <td>0.315920</td>\n",
       "      <td>0.248096</td>\n",
       "      <td>3</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.325926</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.158675</td>\n",
       "      <td>0.098772</td>\n",
       "      <td>0.742554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>decTree</td>\n",
       "      <td>7</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.218877</td>\n",
       "      <td>0.320066</td>\n",
       "      <td>0.251057</td>\n",
       "      <td>2</td>\n",
       "      <td>0.223214</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.055847</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.832653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>decTree</td>\n",
       "      <td>5</td>\n",
       "      <td>[similarityTop3WinesByVariety, tf_grouped_1, t...</td>\n",
       "      <td>0.217363</td>\n",
       "      <td>0.390407</td>\n",
       "      <td>0.279211</td>\n",
       "      <td>2</td>\n",
       "      <td>0.436537</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.563447</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.731003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decTree</td>\n",
       "      <td>7</td>\n",
       "      <td>[similarityTop3WinesByVariety, country, category]</td>\n",
       "      <td>0.216849</td>\n",
       "      <td>0.390547</td>\n",
       "      <td>0.225188</td>\n",
       "      <td>2</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.030189</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>decTree</td>\n",
       "      <td>5</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.215738</td>\n",
       "      <td>0.377514</td>\n",
       "      <td>0.274146</td>\n",
       "      <td>2</td>\n",
       "      <td>0.442584</td>\n",
       "      <td>0.740988</td>\n",
       "      <td>0.554169</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.046090</td>\n",
       "      <td>0.116002</td>\n",
       "      <td>0.837908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>decTree</td>\n",
       "      <td>1</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.204582</td>\n",
       "      <td>0.325503</td>\n",
       "      <td>0.249161</td>\n",
       "      <td>2</td>\n",
       "      <td>0.265805</td>\n",
       "      <td>0.321181</td>\n",
       "      <td>0.290881</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.055008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>decTree</td>\n",
       "      <td>1</td>\n",
       "      <td>[tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...</td>\n",
       "      <td>0.203757</td>\n",
       "      <td>0.322627</td>\n",
       "      <td>0.248447</td>\n",
       "      <td>3</td>\n",
       "      <td>0.263946</td>\n",
       "      <td>0.336806</td>\n",
       "      <td>0.295957</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.157644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithm  ObjectiveCountry  \\\n",
       "8    decTree                 3   \n",
       "16   decTree                 3   \n",
       "11   decTree                 3   \n",
       "7    decTree                 3   \n",
       "9    decTree                 3   \n",
       "14   decTree                 3   \n",
       "19   decTree                 3   \n",
       "6    decTree                 3   \n",
       "21   decTree                 3   \n",
       "26   decTree                 3   \n",
       "13   decTree                 3   \n",
       "18   decTree                 3   \n",
       "24   decTree                 0   \n",
       "29   decTree                 0   \n",
       "7    decTree                 0   \n",
       "11   decTree                 0   \n",
       "16   decTree                 0   \n",
       "8    decTree                 0   \n",
       "23   decTree                 0   \n",
       "28   decTree                 0   \n",
       "9    decTree                 0   \n",
       "21   decTree                 0   \n",
       "26   decTree                 0   \n",
       "29   decTree                 3   \n",
       "22   decTree                 0   \n",
       "27   decTree                 0   \n",
       "24   decTree                 3   \n",
       "22   decTree                 3   \n",
       "27   decTree                 3   \n",
       "6    decTree                 0   \n",
       "..       ...               ...   \n",
       "40   decTree                 2   \n",
       "37   decTree                 9   \n",
       "35   decTree                 9   \n",
       "36   decTree                 9   \n",
       "30   decTree                 1   \n",
       "40   decTree                 8   \n",
       "40   decTree                 4   \n",
       "35   decTree                 4   \n",
       "35   decTree                 8   \n",
       "30   decTree                 4   \n",
       "37   decTree                 4   \n",
       "41   decTree                 6   \n",
       "36   decTree                 4   \n",
       "30   decTree                 6   \n",
       "31   decTree                 6   \n",
       "30   decTree                 9   \n",
       "40   decTree                 7   \n",
       "40   decTree                 1   \n",
       "30   decTree                 5   \n",
       "35   decTree                11   \n",
       "40   decTree                 6   \n",
       "36   decTree                 5   \n",
       "35   decTree                 6   \n",
       "36   decTree                 7   \n",
       "35   decTree                 7   \n",
       "40   decTree                 5   \n",
       "30   decTree                 7   \n",
       "35   decTree                 5   \n",
       "35   decTree                 1   \n",
       "36   decTree                 1   \n",
       "\n",
       "                                                input  precision  accuracy  \\\n",
       "8              [price, word_count, country, category]   0.761018  0.728621   \n",
       "16  [price, vintage, province, region_1, taster_na...   0.759386  0.705635   \n",
       "11  [price, vintage, province, region_1, taster_na...   0.759386  0.705635   \n",
       "7              [price, word_count, country, category]   0.757136  0.718735   \n",
       "9              [price, word_count, country, category]   0.752856  0.732081   \n",
       "14  [price, vintage, province, region_1, taster_na...   0.751701  0.699456   \n",
       "19  [price, vintage, province, region_1, taster_na...   0.751701  0.699456   \n",
       "6              [price, word_count, country, category]   0.750910  0.710826   \n",
       "21  [price, vintage, province, region_1, taster_na...   0.746141  0.703658   \n",
       "26  [price, vintage, province, region_1, taster_na...   0.746141  0.703658   \n",
       "13  [price, vintage, province, region_1, taster_na...   0.743812  0.690559   \n",
       "18  [price, vintage, province, region_1, taster_na...   0.743812  0.690559   \n",
       "24  [price, vintage, province, region_1, taster_na...   0.743010  0.708876   \n",
       "29  [price, vintage, province, region_1, taster_na...   0.741467  0.706509   \n",
       "7              [price, word_count, country, category]   0.738154  0.685799   \n",
       "11  [price, vintage, province, region_1, taster_na...   0.735628  0.644970   \n",
       "16  [price, vintage, province, region_1, taster_na...   0.735628  0.644970   \n",
       "8              [price, word_count, country, category]   0.735563  0.699408   \n",
       "23  [price, vintage, province, region_1, taster_na...   0.734350  0.714497   \n",
       "28  [price, vintage, province, region_1, taster_na...   0.732770  0.709467   \n",
       "9              [price, word_count, country, category]   0.729667  0.711243   \n",
       "21  [price, vintage, province, region_1, taster_na...   0.727089  0.649408   \n",
       "26  [price, vintage, province, region_1, taster_na...   0.727089  0.649408   \n",
       "29  [price, vintage, province, region_1, taster_na...   0.721963  0.733317   \n",
       "22  [price, vintage, province, region_1, taster_na...   0.721026  0.703254   \n",
       "27  [price, vintage, province, region_1, taster_na...   0.721026  0.703254   \n",
       "24  [price, vintage, province, region_1, taster_na...   0.719624  0.732328   \n",
       "22  [price, vintage, province, region_1, taster_na...   0.717692  0.726891   \n",
       "27  [price, vintage, province, region_1, taster_na...   0.717692  0.726891   \n",
       "6              [price, word_count, country, category]   0.716481  0.669527   \n",
       "..                                                ...        ...       ...   \n",
       "40  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.296483  0.268678   \n",
       "37  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.293495  0.469782   \n",
       "35  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.288283  0.454472   \n",
       "36  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.287753  0.452861   \n",
       "30  [similarityTop3WinesByVariety, country, category]   0.287074  0.387824   \n",
       "40  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.276112  0.423152   \n",
       "40  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.275137  0.407228   \n",
       "35  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.274930  0.386983   \n",
       "35  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.273342  0.420349   \n",
       "30  [similarityTop3WinesByVariety, country, category]   0.267216  0.382020   \n",
       "37  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.265644  0.374324   \n",
       "41  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.263946  0.422241   \n",
       "36  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.261545  0.368412   \n",
       "30  [similarityTop3WinesByVariety, country, category]   0.260902  0.404336   \n",
       "31  [similarityTop3WinesByVariety, country, category]   0.260902  0.404336   \n",
       "30  [similarityTop3WinesByVariety, country, category]   0.252575  0.444803   \n",
       "40  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.245752  0.402985   \n",
       "40  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.244888  0.387824   \n",
       "30  [similarityTop3WinesByVariety, country, category]   0.243287  0.352759   \n",
       "35  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.235263  0.375401   \n",
       "40  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.234019  0.395712   \n",
       "36  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.222038  0.287261   \n",
       "35  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.220856  0.377747   \n",
       "36  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.218883  0.315920   \n",
       "35  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.218877  0.320066   \n",
       "40  [similarityTop3WinesByVariety, tf_grouped_1, t...   0.217363  0.390407   \n",
       "30  [similarityTop3WinesByVariety, country, category]   0.216849  0.390547   \n",
       "35  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.215738  0.377514   \n",
       "35  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.204582  0.325503   \n",
       "36  [tf_grouped_1, tf_grouped_2, tf_grouped_3, cou...   0.203757  0.322627   \n",
       "\n",
       "          f1  depth  low_prec  low_recall    low_f1        ...          \\\n",
       "8   0.740264      5  0.506667    0.674556  0.578680        ...           \n",
       "16  0.720397      3  0.600000    0.461538  0.521739        ...           \n",
       "11  0.720397      3  0.600000    0.461538  0.521739        ...           \n",
       "7   0.732052      4  0.531486    0.624260  0.574150        ...           \n",
       "9   0.739606      6  0.483936    0.713018  0.576555        ...           \n",
       "14  0.715948      6  0.507109    0.633136  0.563158        ...           \n",
       "19  0.715948      6  0.507109    0.633136  0.563158        ...           \n",
       "6   0.724421      3  0.458647    0.721893  0.560920        ...           \n",
       "21  0.716443      3  0.600000    0.461538  0.521739        ...           \n",
       "26  0.716443      3  0.600000    0.461538  0.521739        ...           \n",
       "13  0.707416      5  0.432479    0.748521  0.548212        ...           \n",
       "18  0.707416      5  0.432479    0.748521  0.548212        ...           \n",
       "24  0.720585      6  0.643510    0.727273  0.682832        ...           \n",
       "29  0.718321      6  0.631206    0.735537  0.679389        ...           \n",
       "7   0.702064      4  0.676409    0.669421  0.672897        ...           \n",
       "11  0.667010      3  0.707989    0.530992  0.606848        ...           \n",
       "16  0.667010      3  0.707989    0.530992  0.606848        ...           \n",
       "8   0.711634      5  0.634234    0.727273  0.677575        ...           \n",
       "23  0.722421      5  0.653226    0.669421  0.661224        ...           \n",
       "28  0.718516      5  0.653226    0.669421  0.661224        ...           \n",
       "9   0.718133      6  0.621528    0.739669  0.675472        ...           \n",
       "21  0.669809      3  0.707989    0.530992  0.606848        ...           \n",
       "26  0.669809      3  0.707989    0.530992  0.606848        ...           \n",
       "29  0.726335      6  0.562842    0.609467  0.585227        ...           \n",
       "22  0.707909      4  0.561863    0.797521  0.659266        ...           \n",
       "27  0.707909      4  0.561863    0.797521  0.659266        ...           \n",
       "24  0.724400      6  0.563187    0.606509  0.584046        ...           \n",
       "22  0.717972      4  0.498978    0.721893  0.590085        ...           \n",
       "27  0.717972      4  0.498978    0.721893  0.590085        ...           \n",
       "6   0.683655      3  0.555060    0.770661  0.645329        ...           \n",
       "..       ...    ...       ...         ...       ...        ...           \n",
       "40  0.221781      2  0.608264    0.297735  0.399783        ...           \n",
       "37  0.360330      4  0.317518    0.402778  0.355102        ...           \n",
       "35  0.352772      2  0.277946    0.425926  0.336380        ...           \n",
       "36  0.351899      3  0.277612    0.430556  0.337568        ...           \n",
       "30  0.245239      2  0.530612    0.090278  0.154303        ...           \n",
       "40  0.295410      2  0.363426    0.126613  0.187799        ...           \n",
       "40  0.326526      2  0.409787    0.511342  0.454966        ...           \n",
       "35  0.289548      2  0.443263    0.263176  0.330265        ...           \n",
       "35  0.290013      2  0.358056    0.112903  0.171674        ...           \n",
       "30  0.308981      2  0.000000    0.000000  0.000000        ...           \n",
       "37  0.269035      4  0.423466    0.200068  0.271748        ...           \n",
       "41  0.323321      3  0.333162    0.650841  0.440721        ...           \n",
       "36  0.257863      3  0.415301    0.168514  0.239748        ...           \n",
       "30  0.311904      2  0.319038    0.710123  0.440274        ...           \n",
       "31  0.311904      3  0.319038    0.710123  0.440274        ...           \n",
       "30  0.309182      2  0.218750    0.097222  0.134615        ...           \n",
       "40  0.304912      2  0.287846    0.535714  0.374480        ...           \n",
       "40  0.293063      2  0.348432    0.347222  0.347826        ...           \n",
       "30  0.271520      2  0.525721    0.559413  0.542044        ...           \n",
       "35  0.235125      2  0.305079    0.058913  0.098755        ...           \n",
       "40  0.281831      2  0.352197    0.293896  0.320416        ...           \n",
       "36  0.222780      3  0.486842    0.395194  0.436256        ...           \n",
       "35  0.271804      2  0.308435    0.304949  0.306682        ...           \n",
       "36  0.248096      3  0.222222    0.611111  0.325926        ...           \n",
       "35  0.251057      2  0.223214    0.595238  0.324675        ...           \n",
       "40  0.279211      2  0.436537    0.794393  0.563447        ...           \n",
       "30  0.225188      2  0.307692    0.015873  0.030189        ...           \n",
       "35  0.274146      2  0.442584    0.740988  0.554169        ...           \n",
       "35  0.249161      2  0.265805    0.321181  0.290881        ...           \n",
       "36  0.248447      3  0.263946    0.336806  0.295957        ...           \n",
       "\n",
       "    feat_province  feat_region_1  feat_taster_name  feat_variety  feat_winery  \\\n",
       "8      100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "16       0.000000       0.000000          0.076084      0.000000     0.000000   \n",
       "11       0.000000       0.000000          0.076084      0.000000     0.000000   \n",
       "7      100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "9      100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "14       0.022199       0.024663          0.097252      0.000670     0.001295   \n",
       "19       0.017915       0.021011          0.093846      0.000728     0.000855   \n",
       "6      100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "21       0.000000       0.000000          0.051819      0.000000     0.000000   \n",
       "26       0.000000       0.000000          0.051819      0.000000     0.000000   \n",
       "13       0.011277       0.023257          0.080463      0.000000     0.000000   \n",
       "18       0.011263       0.021490          0.079200      0.000000     0.000000   \n",
       "24       0.006943       0.003812          0.083260      0.001827     0.000000   \n",
       "29       0.006233       0.003803          0.082216      0.000000     0.000000   \n",
       "7      100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "11       0.000000       0.000000          0.075165      0.000000     0.000000   \n",
       "16       0.000000       0.000000          0.075165      0.000000     0.000000   \n",
       "8      100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "23       0.000000       0.001964          0.083502      0.000000     0.000000   \n",
       "28       0.000000       0.001963          0.083463      0.000000     0.000000   \n",
       "9      100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "21       0.000000       0.000000          0.051261      0.000000     0.000000   \n",
       "26       0.000000       0.000000          0.051261      0.000000     0.000000   \n",
       "29       0.005724       0.012410          0.077431      0.000000     0.000000   \n",
       "22       0.000000       0.000000          0.077687      0.000000     0.000000   \n",
       "27       0.000000       0.000000          0.077687      0.000000     0.000000   \n",
       "24       0.006868       0.012443          0.078627      0.002900     0.000000   \n",
       "22       0.000000       0.000000          0.078176      0.000000     0.000000   \n",
       "27       0.000000       0.000000          0.078176      0.000000     0.000000   \n",
       "6      100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "..            ...            ...               ...           ...          ...   \n",
       "40     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "37     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "35     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "36     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "30     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "40     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "40     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "35     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "35     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "30     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "37     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "41     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "36     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "30     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "31     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "30     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "40     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "40     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "30     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "35     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "40     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "36     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "35     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "36     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "35     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "40     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "30     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "35     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "35     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "36     100.000000     100.000000        100.000000    100.000000   100.000000   \n",
       "\n",
       "    feat_word_count  feat_similarityTop3WinesByVariety  feat_tf_grouped_1  \\\n",
       "8          0.220698                         100.000000         100.000000   \n",
       "16       100.000000                         100.000000           0.000000   \n",
       "11       100.000000                         100.000000         100.000000   \n",
       "7          0.212848                         100.000000         100.000000   \n",
       "9          0.231704                         100.000000         100.000000   \n",
       "14       100.000000                         100.000000         100.000000   \n",
       "19       100.000000                         100.000000           0.005038   \n",
       "6          0.160747                         100.000000         100.000000   \n",
       "21       100.000000                           0.030755         100.000000   \n",
       "26       100.000000                           0.030755           0.000000   \n",
       "13       100.000000                         100.000000         100.000000   \n",
       "18       100.000000                         100.000000           0.003897   \n",
       "24       100.000000                           0.118335         100.000000   \n",
       "29       100.000000                           0.116774           0.001625   \n",
       "7          0.208156                         100.000000         100.000000   \n",
       "11       100.000000                         100.000000         100.000000   \n",
       "16       100.000000                         100.000000           0.000000   \n",
       "8          0.215145                         100.000000         100.000000   \n",
       "23       100.000000                           0.101612         100.000000   \n",
       "28       100.000000                           0.098923           0.000000   \n",
       "9          0.224951                         100.000000         100.000000   \n",
       "21       100.000000                           0.030008         100.000000   \n",
       "26       100.000000                           0.030008           0.000000   \n",
       "29       100.000000                           0.115057           0.000000   \n",
       "22       100.000000                           0.084827         100.000000   \n",
       "27       100.000000                           0.084827           0.000000   \n",
       "24       100.000000                           0.116650         100.000000   \n",
       "22       100.000000                           0.087968         100.000000   \n",
       "27       100.000000                           0.087968           0.000000   \n",
       "6          0.156641                         100.000000         100.000000   \n",
       "..              ...                                ...                ...   \n",
       "40       100.000000                           0.716919           0.000000   \n",
       "37       100.000000                         100.000000           0.252547   \n",
       "35       100.000000                         100.000000           0.058303   \n",
       "36       100.000000                         100.000000           0.162240   \n",
       "30       100.000000                           1.000000         100.000000   \n",
       "40       100.000000                           0.729237           0.000000   \n",
       "40       100.000000                           0.723602           0.000000   \n",
       "35       100.000000                         100.000000           0.057587   \n",
       "35       100.000000                         100.000000           0.063424   \n",
       "30       100.000000                           1.000000         100.000000   \n",
       "37       100.000000                         100.000000           0.164255   \n",
       "41       100.000000                           0.758013           0.000000   \n",
       "36       100.000000                         100.000000           0.155963   \n",
       "30       100.000000                           1.000000         100.000000   \n",
       "31       100.000000                           1.000000         100.000000   \n",
       "30       100.000000                           1.000000         100.000000   \n",
       "40       100.000000                           0.724221           0.000000   \n",
       "40       100.000000                           0.717126           0.000000   \n",
       "30       100.000000                           1.000000         100.000000   \n",
       "35       100.000000                         100.000000           0.717612   \n",
       "40       100.000000                           0.726824           0.000000   \n",
       "36       100.000000                         100.000000           0.148244   \n",
       "35       100.000000                         100.000000           0.037349   \n",
       "36       100.000000                         100.000000           0.158675   \n",
       "35       100.000000                         100.000000           0.055847   \n",
       "40       100.000000                           0.731003           0.000000   \n",
       "30       100.000000                           1.000000         100.000000   \n",
       "35       100.000000                         100.000000           0.046090   \n",
       "35       100.000000                         100.000000           0.055008   \n",
       "36       100.000000                         100.000000           0.157644   \n",
       "\n",
       "    feat_tf_grouped_2  feat_tf_grouped_3  \n",
       "8          100.000000         100.000000  \n",
       "16           0.000000           0.000000  \n",
       "11         100.000000         100.000000  \n",
       "7          100.000000         100.000000  \n",
       "9          100.000000         100.000000  \n",
       "14         100.000000         100.000000  \n",
       "19           0.005682           0.008546  \n",
       "6          100.000000         100.000000  \n",
       "21         100.000000         100.000000  \n",
       "26           0.000000           0.000000  \n",
       "13         100.000000         100.000000  \n",
       "18           0.000778           0.000000  \n",
       "24         100.000000         100.000000  \n",
       "29           0.002745           0.007574  \n",
       "7          100.000000         100.000000  \n",
       "11         100.000000         100.000000  \n",
       "16           0.000000           0.000000  \n",
       "8          100.000000         100.000000  \n",
       "23         100.000000         100.000000  \n",
       "28           0.002895           0.001422  \n",
       "9          100.000000         100.000000  \n",
       "21         100.000000         100.000000  \n",
       "26           0.000000           0.000000  \n",
       "29           0.004519           0.007023  \n",
       "22         100.000000         100.000000  \n",
       "27           0.000000           0.000000  \n",
       "24         100.000000         100.000000  \n",
       "22         100.000000         100.000000  \n",
       "27           0.000000           0.000000  \n",
       "6          100.000000         100.000000  \n",
       "..                ...                ...  \n",
       "40           0.000000           0.283081  \n",
       "37           0.086869           0.660584  \n",
       "35           0.110743           0.830954  \n",
       "36           0.097926           0.739834  \n",
       "30         100.000000         100.000000  \n",
       "40           0.000000           0.270763  \n",
       "40           0.000000           0.276398  \n",
       "35           0.000000           0.942413  \n",
       "35           0.105744           0.830832  \n",
       "30         100.000000         100.000000  \n",
       "37           0.004520           0.831225  \n",
       "41           0.000000           0.241987  \n",
       "36           0.000000           0.844037  \n",
       "30         100.000000         100.000000  \n",
       "31         100.000000         100.000000  \n",
       "30         100.000000         100.000000  \n",
       "40           0.000000           0.275779  \n",
       "40           0.000000           0.282874  \n",
       "30         100.000000         100.000000  \n",
       "35           0.000000           0.282388  \n",
       "40           0.000000           0.273176  \n",
       "36           0.100971           0.750785  \n",
       "35           0.066584           0.896067  \n",
       "36           0.098772           0.742554  \n",
       "35           0.111500           0.832653  \n",
       "40           0.000000           0.268997  \n",
       "30         100.000000         100.000000  \n",
       "35           0.116002           0.837908  \n",
       "35           0.000000           0.944992  \n",
       "36           0.000000           0.842356  \n",
       "\n",
       "[540 rows x 31 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.sort_values([\"precision\",\"f1\",\"accuracy\"],ascending=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot scatter plot for visualizing bins by color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot radar plot to visualize most important features for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot radar plot for features in dectree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data\n",
    "df = pd.DataFrame({\n",
    "'group': ['A','B','C','D'],\n",
    "'var1': [38, 1.5, 30, 4],\n",
    "'var2': [29, 10, 9, 34],\n",
    "'var3': [8, 39, 23, 24],\n",
    "'var4': [7, 31, 33, 14],\n",
    "'var5': [28, 15, 32, 14]\n",
    "})\n",
    " \n",
    "# ------- PART 1: Define a function that do a plot for one line of the dataset!\n",
    " \n",
    "def make_spider( row, title, color):\n",
    "    categories=list(df)[1:]\n",
    "    N = len(categories)\n",
    "\n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * math.pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    # Initialise the spider plot\n",
    "    ax = plt.subplot(2,2,row+1, polar=True, )\n",
    "\n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(math.pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], categories, color='grey', size=8)\n",
    "\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([10,20,30], [\"10\",\"20\",\"30\"], color=\"grey\", size=7)\n",
    "    plt.ylim(0,40)\n",
    "\n",
    "    # Ind1\n",
    "    values=df.loc[row].drop('group').values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, color=color, linewidth=2, linestyle='solid')\n",
    "    ax.fill(angles, values, color=color, alpha=0.4)\n",
    "\n",
    "    # Add a title\n",
    "    plt.title(title, size=11, color=color, y=1.1)\n",
    "\n",
    "# ------- PART 2: Apply to all individuals\n",
    "# initialize the figure\n",
    "my_dpi=96\n",
    "plt.figure(figsize=(1000/my_dpi, 1000/my_dpi), dpi=my_dpi)\n",
    " \n",
    "# Create a color palette:\n",
    "my_palette = plt.cm.get_cmap(\"Set2\", len(df.index))\n",
    " \n",
    "# Loop to plot\n",
    "for row in range(0, len(df.index)):\n",
    "    make_spider( row=row, title='group '+df['group'][row], color=my_palette(row))\n",
    "\n",
    "categories=list(df)[1:]\n",
    "N = len(categories)\n",
    " \n",
    "# What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "angles = [n / float(N) * 2 * math.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    " \n",
    "# Initialise the spider plot\n",
    "ax = plt.subplot(2,2,row+1, polar=True, )\n",
    " \n",
    "# If you want the first axis to be on top:\n",
    "ax.set_theta_offset(math.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    " \n",
    "# Draw one axe per variable + add labels labels yet\n",
    "plt.xticks(angles[:-1], categories, color='grey', size=8)\n",
    " \n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([10,20,30], [\"10\",\"20\",\"30\"], color=\"grey\", size=7)\n",
    "plt.ylim(0,40)\n",
    " \n",
    "# Ind1\n",
    "values=df.loc[row].drop('group').values.flatten().tolist()\n",
    "values += values[:1]\n",
    "ax.plot(angles, values, color=color, linewidth=2, linestyle='solid')\n",
    "ax.fill(angles, values, color=color, alpha=0.4)\n",
    " \n",
    "# Add a title\n",
    "plt.title(title, size=11, color=color, y=1.1)\n",
    " \n",
    "# ------- PART 2: Apply to all individuals\n",
    "# initialize the figure\n",
    "my_dpi=96\n",
    "plt.figure(figsize=(1000/my_dpi, 1000/my_dpi), dpi=my_dpi)\n",
    " \n",
    "# Create a color palette:\n",
    "my_palette = plt.cm.get_cmap(\"Set2\", len(df.index))\n",
    " \n",
    "# Loop to plot\n",
    "for row in range(0, len(df.index)):\n",
    "    make_spider( row=row, title='group '+df['group'][row], color=my_palette(row))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
