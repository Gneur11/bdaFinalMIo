{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelBinarizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score,precision_recall_fscore_support,f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from pandas.tools.plotting import parallel_coordinates\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_base = pd.read_csv(\"Our_dataset/StemmedWord2vecTop3_parsed.csv\", index_col=0) \n",
    "wine_base = wine_base.reset_index()\n",
    "wine_base= wine_base[pd.notnull(wine_base['description'])]\n",
    "wine_base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in wine_base.columns:\n",
    "    if(col.startswith(\"tf\")):\n",
    "            wine_base.drop(col,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_vintage(df):\n",
    "    pattern = r\"\\d{4}\"\n",
    "    vintages = []\n",
    "    for elem in df.title:\n",
    "        match = re.findall(pattern,elem)\n",
    "        year = 0\n",
    "        if len(match)>1:\n",
    "            y= int(match[0])\n",
    "            if y <1952:\n",
    "                year = 0\n",
    "            elif y==3000:\n",
    "                year == 2009\n",
    "            elif y == 7200:\n",
    "                year = int(match[1])\n",
    "            else:\n",
    "                year= y\n",
    "        elif len(match)==1:\n",
    "            y= int(match[0])\n",
    "            if y <1952:\n",
    "                year = 0\n",
    "            elif y==3000:\n",
    "                year == 2009\n",
    "            elif year == 7200:\n",
    "                year = 0\n",
    "            else:\n",
    "                year = y\n",
    "        else:\n",
    "            year = 0\n",
    "        vintages.append(year)\n",
    "\n",
    "    se = pd.Series(vintages)\n",
    "    df['vintage']=se.values \n",
    "    df.drop('title',axis=1)\n",
    "    return df\n",
    "\n",
    "wine_base = get_vintage(wine_base)\n",
    "#drop reviwe of wine with ventage =0\n",
    "wine_base = wine_base[wine_base.vintage != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_base = wine_base[pd.notnull(wine_base['country'])]\n",
    "wine_base = wine_base[pd.notnull(wine_base['taster_name'])]\n",
    "wine_base = wine_base[pd.notnull(wine_base[\"variety\"])]\n",
    "wine_base = wine_base[pd.notnull(wine_base[\"province\"])]\n",
    "wine_base = wine_base[pd.notnull(wine_base[\"winery\"])]\n",
    "\n",
    "wine_base.drop(\"title\",inplace=True,axis=1)\n",
    "wine_base = wine_base.dropna()\n",
    "\n",
    "#keep track of the countries,provinces,taster_names in the database\n",
    "countries = wine_base[\"country\"].unique().tolist()\n",
    "provinces = wine_base[\"province\"].unique().tolist()\n",
    "tasters = wine_base[\"taster_name\"].unique().tolist()\n",
    "\n",
    "def OneHotEncode(dataframe,column_to_encode,take_whole_dataset=True):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(dataframe[[column_to_encode]])\n",
    "    mapping = {}\n",
    "    i=0\n",
    "    for elem in enc.categories_[0]:\n",
    "        mapping[elem]=i\n",
    "        i+=1\n",
    "    resu = enc.transform(dataframe[[column_to_encode]]).toarray()\n",
    "    if take_whole_dataset:\n",
    "        for elem in mapping:\n",
    "            dataframe[elem]=resu[:,mapping[elem]]\n",
    "        return dataframe\n",
    "    else:\n",
    "        subset = dataframe[[column_to_encode]]\n",
    "        for elem in mapping:\n",
    "            subset[elem]=resu[:,mapping[elem]]\n",
    "        return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_base = OneHotEncode(wine_base,'taster_name')\n",
    "wine_base = wine_base.drop('taster_name', 1)\n",
    "wine_base = OneHotEncode(wine_base,'province')\n",
    "wine_base = wine_base.drop('province', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_base.drop([\"designation\",\"description\"],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "\n",
    "wine_base[\"winery\"] = wine_base[\"winery\"].astype('category').cat.codes\n",
    "wine_base[\"region_1\"] = wine_base[\"region_1\"].astype('category').cat.codes\n",
    "wine_base[\"variety\"] = wine_base[\"variety\"].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 5))\n",
    "sns.distplot(wine_base[\"points\"],hist=True,bins = 20,hist_kws={'edgecolor':'black'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wine2 = pd.DataFrame()\n",
    "wine2 = wine_base\n",
    "nbins  = 3\n",
    "labels=[\"low\",\"medium\",\"high\"]\n",
    "g,b = pd.qcut(wine2[\"points\"],nbins,labels=labels,retbins=True)   #uses quartiles and statistic stuff\n",
    "g.tolist()\n",
    "wine2[\"category\"] = g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wine2.drop(\"description\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parallel coordinates would be nice\n",
    "\n",
    "low = wine2[wine2[\"category\"] == \"low\"]\n",
    "medium = wine2[wine2[\"category\"] == \"medium\"]\n",
    "high = wine2[wine2[\"category\"] == \"high\"]\n",
    "\n",
    "wine3 = pd.DataFrame()\n",
    "features = [\"category\",'vintage', 'country', 'points', 'price', 'province','region_1', 'taster_name', 'variety', 'winery','similarityTop3WinesByVariety', 'word_count']\n",
    "for feat in features:\n",
    "    wine3[feat] = wine2[feat]\n",
    "fig, ax = plt.subplots(figsize = (25, 10))\n",
    "parallel_coordinates(wine3, 'category', colormap=plt.get_cmap(\"Set2\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE NUMBER OF BINS = classes to be predicted (must be executed so that Y is the same for every execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = wine_base['points'].copy()\n",
    "#DECIDE NUMBER OF BINS \n",
    "#nbins  = 4\n",
    "#labels=[\"low\",\"medium\",\"high\",\"very_high\"]\n",
    "#nbins = 5\n",
    "#labels=[\"very_low\", \"low\", \"medium\",\"high\",\"very_high\"]\n",
    "#bin identici \n",
    "#Y,bins = pd.cut(Y,nbins,labels=labels,retbins=True,include_lowest=True,right=True)\n",
    "#quartile\n",
    "nbins  = 3\n",
    "labels=[\"low\",\"medium\",\"high\"]\n",
    "Y,bins = pd.qcut(Y,nbins,labels=labels,retbins=True)   #uses quartiles and statistic stuff\n",
    "values = Y.tolist()  \n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the binning result\n",
    "fig, ax = plt.subplots(figsize = (12, 5))\n",
    "for i in range(1,len(bins)-1):\n",
    "\n",
    "    if i == 1:\n",
    "        a = wine_base[wine_base[\"points\"] <= bins[i]]\n",
    "        n =  bins[i]-80\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "        g =+n\n",
    "    if i == len(bins)-1:\n",
    "        a = wine_base[wine_base[\"points\"] > bins[i]]\n",
    "        n = 100 - bins[i]\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "        g =+ n\n",
    "    else:\n",
    "        n = bins[i+1] - bins[i]\n",
    "        g =+n\n",
    "        a = wine_base[(wine_base[\"points\"] > bins[i]) & (wine_base[\"points\"] <= bins[i+1])]\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "ax.set(xticks=wine_base[\"points\"].unique())\n",
    "print(g)\n",
    "sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic = [\"price\",'vintage', 'country', 'province', 'region_1', 'taster_name', 'variety','winery']\n",
    "word = [\"word_count\"]\n",
    "#tfGroup = ['tf_grouped_1','tf_grouped_2', 'tf_grouped_3']\n",
    "#tfIdfGroup = ['tfIdf_grouped_1', 'tfIdf_grouped_2', 'tfIdf_grouped_3']\n",
    "#tfFull = ['tf_fullData_1', 'tf_fullData_2', 'tf_fullData_3',]\n",
    "#tfIdfFull = ['tfIdf_fullData_1', 'tfIdf_fullData_2', 'tfIdf_fullData_3']\n",
    "#weather = ['pr_5', 'pr_6', 'pr_7', 'pr_8', 'pr_9', 'tas_5', 'tas_6', 'tas_7', 'tas_8', 'tas_9']# don't really care bcs 0 improvements\n",
    "word2vec = ['similarityTop3WinesByVariety']\n",
    "features = basic + word + word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test stuff based on countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = wine_base[\"country\"].unique().tolist()\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in countries:\n",
    "    print(c,len(wine_base[wine_base[\"country\"] == c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = wine_base[\"country\"].unique().tolist()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testByCountry(data,countries):\n",
    "    #for every country, use it as test set\n",
    "    nbins  = 3\n",
    "    labels=[\"low\",\"medium\",\"high\"]\n",
    "    wine2 = pd.DataFrame()\n",
    "    wine2 = data\n",
    "    g,b = pd.qcut(data[\"points\"],nbins,labels=labels,retbins=True)   #uses quartiles and statistic stuff\n",
    "    g.tolist()\n",
    "    wine3 = wine2.drop([\"points\"],axis=1)\n",
    "    wine3[\"category\"] = g\n",
    "    df = pd.DataFrame()\n",
    "    for el in countries:\n",
    "        res = applyTest(wine3,el)\n",
    "        df = df.append(res)\n",
    "    return df\n",
    "\n",
    "def applyTest(data,objCountry):\n",
    "  \n",
    "    #set many different combinations\n",
    "    #only on these\n",
    "    allfeatures = []\n",
    "    args = []\n",
    "    for el in wine_base.columns:\n",
    "        if el != \"description\":\n",
    "            allfeatures.append(el)   \n",
    "        if el != \"description\" and el != \"points\" and el != \"country\":\n",
    "            args.append(el)\n",
    "    combos = {\"depth\":[2,3,4,5,6],\"args\":[args]}\n",
    "    #\n",
    "    res = buildCountryResult(data,args,allfeatures,combos,objCountry)\n",
    "    return res\n",
    "\n",
    "def buildCountryResult(data,args,allfeatures,combination,objCountry):\n",
    "    cols = [\"algorithm\",\"ObjectiveCountry\",\"input\",\"precision\",\"accuracy\",\"f1\",\"depth\"]\n",
    "    algorithm = \"decTree\"\n",
    "    for lab in labels:\n",
    "        cols.append(lab +\"_prec\")\n",
    "        cols.append(lab +\"_recall\")\n",
    "        cols.append(lab +\"_f1\")\n",
    "        cols.append(lab +\"_support\")\n",
    "    for el in args: #controlla che allfeats vada bene\n",
    "        c = \"feat_\"+el\n",
    "        if c not in cols:\n",
    "            cols.append(c)\n",
    "    results = pd.DataFrame()\n",
    "    comb = 0\n",
    "    row = 0\n",
    "    for el in combination[\"args\"]: \n",
    "        el = el + [\"country\",\"category\"]\n",
    "        X = data[el]\n",
    "        #create test and training sets\n",
    "        X_train = X[X[\"country\"] != objCountry]\n",
    "        y_train = pd.DataFrame()\n",
    "        y_train = list(X_train[\"category\"])\n",
    "        print(objCountry +\" must not be in training set \" + str(X_train[\"country\"].unique().tolist()))\n",
    "        X_train.drop([\"country\",\"category\"],axis=1,inplace=True)\n",
    "\n",
    "        X_test = X[X[\"country\"] == objCountry]\n",
    "        y_test = X_test[\"category\"]\n",
    "        X_test.drop([\"country\",\"category\"],axis=1,inplace=True)\n",
    "        for depth in combination[\"depth\"]:\n",
    "                row = row + 1  \n",
    "                #train stuff\n",
    "                classifier = DecisionTreeClassifier(max_depth=depth)\n",
    "                classifier.fit(X_train,y_train)\n",
    "                y_pred = classifier.predict(X_test)  \n",
    "                acc = accuracy_score(y_test,y_pred)#average=\"macro\")\n",
    "                weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "                f1 = f1_score(y_test,y_pred,average=\"weighted\")\n",
    "                rowData = [algorithm,objCountry,el,weightedPrec,acc,f1,depth]\n",
    "                precision,recall,fscore,support = precision_recall_fscore_support(y_test, y_pred)\n",
    "                for i in range(0,len(labels)):\n",
    "                    rowData.append(precision[i])\n",
    "                    rowData.append(recall[i])\n",
    "                    rowData.append(fscore[i])\n",
    "                    rowData.append(support[i])\n",
    "                    temp = {}\n",
    "                c = zip(el,classifier.feature_importances_)\n",
    "                names = []\n",
    "                for name,importance in c:\n",
    "                    temp[name] = importance\n",
    "                    names.append(name)\n",
    "                for feat in names:\n",
    "                    #if feat not in allfeatures:\n",
    "                     #   rowData.append(100) #100 is an impossible value not to be taken into account\n",
    "                    #else:\n",
    "                        rowData.append(temp[feat]) #qualcosa non quadra con le liste di input e colonne per appendere i dataframe con le relative feature importances\n",
    "                df2 = pd.DataFrame([rowData],columns=cols)\n",
    "                results = results.append(df2,ignore_index=True)\n",
    "        comb = comb + 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basic = [\"price\",'vintage', 'province', 'region_1', 'taster_name', 'variety','winery'] #country non deve esserci \n",
    "word = [\"word_count\"]\n",
    "word2vec = ['similarityTop3WinesByVariety']\n",
    "features = []\n",
    "for el in wine_base.columns:\n",
    "    if el != \"description\":\n",
    "        features.append(el)\n",
    "\n",
    "result = testByCountry(wine_base,countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop(\"input\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in result.columns:\n",
    "    if len(result[col].unique().tolist()) == 1:\n",
    "        result.drop(col,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there are combinations of country/depth for every country, if we take the first row every 5 we have the best result\n",
    "result = result.sort_values([\"ObjectiveCountry\",\"f1\"],ascending=False)\n",
    "df = pd.DataFrame()\n",
    "df = result.reset_index(drop=True)    \n",
    "df = df.iloc[::5, :]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse general country stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot accuracy, precision, f1 for every country (f1=weighted average of precision, recall)\n",
    "temp = pd.DataFrame()\n",
    "temp = df.loc[:,[\"ObjectiveCountry\",\"precision\",\"accuracy\",\"f1\"]]\n",
    "temp = temp.sort_values([\"precision\",\"f1\",\"accuracy\"],ascending=False)\n",
    "# width of the bars\n",
    "barWidth = 0.25\n",
    " \n",
    "# Choose the height of the blue bars\n",
    "bars1 = temp[\"precision\"]\n",
    "# Choose the height of the cyan bars\n",
    "bars2 = temp[\"accuracy\"]\n",
    "\n",
    "bars3 = temp[\"f1\"]\n",
    "\n",
    "# The x position of bars\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "fig, ax = plt.subplots(figsize = (14, 5))\n",
    "\n",
    "# Create blue bars\n",
    "plt.bar(r1, bars1, width = barWidth, color = \"#b2df8a\", edgecolor = 'black', capsize=7, label='precision')\n",
    " \n",
    "# Create cyan bars\n",
    "plt.bar(r2, bars2, width = barWidth, color = '#1f78b4', edgecolor = 'black', capsize=7, label='accuracy')\n",
    "\n",
    "plt.bar(r3, bars3, width = barWidth, color = \"#a6cee3\", edgecolor = 'black', capsize=7, label='f1')\n",
    "\n",
    "xs = temp[\"ObjectiveCountry\"].unique().tolist()\n",
    "# general layout\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], xs)\n",
    "plt.ylabel('%')\n",
    "plt.legend()\n",
    " \n",
    "# Show graphic\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot f1 by category predicted \n",
    "temp = pd.DataFrame()\n",
    "temp = df.loc[:,[\"ObjectiveCountry\",\"low_prec\",\"medium_prec\",\"high_prec\"]]\n",
    "temp = temp.sort_values([\"medium_prec\",\"high_prec\",\"low_prec\"],ascending=False)\n",
    "temp\n",
    "\n",
    "# width of the bars\n",
    "barWidth = 0.25\n",
    " \n",
    "# Choose the height of the blue bars\n",
    "bars1 = temp[\"low_prec\"]\n",
    "# Choose the height of the cyan bars\n",
    "bars2 = temp[\"medium_prec\"]\n",
    "\n",
    "bars3 = temp[\"high_prec\"]\n",
    "\n",
    "# The x position of bars\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "fig, ax = plt.subplots(figsize = (14, 5))\n",
    "\n",
    "# Create blue bars\n",
    "plt.bar(r1, bars1, width = barWidth, color = \"#fee6ce\", edgecolor = 'black', capsize=7, label='low')\n",
    " \n",
    "# Create cyan bars\n",
    "plt.bar(r2, bars2, width = barWidth, color = '#fdae6b', edgecolor = 'black', capsize=7, label='medium')\n",
    "\n",
    "plt.bar(r3, bars3, width = barWidth, color = \"#e6550d\", edgecolor = 'black', capsize=7, label='high')\n",
    "\n",
    "ys = temp[\"ObjectiveCountry\"].unique().tolist()\n",
    "# general layout\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], ys)\n",
    "plt.ylabel('%')\n",
    "plt.legend()\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per country, visualize  what influences the decision tree \n",
    "IT DOESN'T TAKE INTO ACCOUNT PRICE BECAUSE IT WOULD MAKE EVERY KIND OF VISUALIZATION USELESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take mean of all the features used in the computations of decision tree to see the by country and understand which factors play into a country \n",
    "\n",
    "features = []\n",
    "for col in df.columns:\n",
    "    if col.startswith(\"feat\"):\n",
    "        features.append(col)\n",
    "print(features)\n",
    "\n",
    "t1 = pd.DataFrame()\n",
    "t = result.groupby(\"ObjectiveCountry\")\n",
    "for col in features: \n",
    "    t1[col] = t[col].mean() \n",
    "t1.reset_index(inplace=True)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "t2 = t1.drop([\"ObjectiveCountry\"],axis=1)\n",
    "x = t2.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "t3 = pd.DataFrame(x_scaled,columns=t2.columns)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for idx,row in t3.iterrows():\n",
    "    toPlot = []\n",
    "    values = []\n",
    "    for col in t3.columns:  \n",
    "        if row[col] != 0 and col != \"ObjectiveCountry\" and col != \"feat_price\":    #ignore price\n",
    "            toPlot.append(col)\n",
    "            values.append(row[col])\n",
    "    print(toPlot)\n",
    "    print(values)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (9, 9))\n",
    "    # create data\n",
    "    names= toPlot  \n",
    "    size= values\n",
    "    colors =['#91cf60','#d73027','#fc8d59','#ffffbf','#d9ef8b','#fee08b','#1a9850']\n",
    "    # Create a circle for the center of the plot\n",
    "    my_circle=plt.Circle((0,0), 0.70, fc='white')\n",
    "    plt.title(\"Target country: \"+ t1.iloc[idx][\"ObjectiveCountry\"])\n",
    "    patches, texts, autotexts = ax.pie(size, labels=names, autopct='%1.1f%%', startangle=90,colors=colors)\n",
    "    for text in texts:\n",
    "        text.set_color('grey')\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('grey')\n",
    "    \n",
    "    ax.axis('equal')  \n",
    "\n",
    "    plt.tight_layout()\n",
    "    p=plt.gcf()\n",
    "    p.gca().add_artist(my_circle)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in t3.iterrows():\n",
    "    both = []\n",
    "    for col in t3.columns:\n",
    "        if row[col] != 0 and col != \"ObjectiveCountry\" and col != \"feat_price\":    #ignore price\n",
    "            both.append([col,row[col]])\n",
    "    #print(toPlot)\n",
    "    #print(values)\n",
    "    \n",
    "    from operator import itemgetter\n",
    "    both = sorted(both, key=itemgetter(1))\n",
    "    print(both)\n",
    "    \n",
    "    toPlot = []\n",
    "    values = []    \n",
    "    for el in both:\n",
    "        toPlot.append(el[0])\n",
    "        values.append(el[1])\n",
    "    \n",
    "    # width of the bars\n",
    "    barWidth = 0.5\n",
    "    \n",
    "    # Choose the height of the blue bars\n",
    "    bars1 = values\n",
    "\n",
    "    # The x position of bars\n",
    "    r1 = np.arange(len(toPlot))\n",
    "    fig, ax = plt.subplots(figsize = (10, 7))\n",
    "\n",
    "    # Create blue bars\n",
    "    plt.barh(r1, bars1, height=barWidth, color = \"#a6cee3\", edgecolor = 'black', capsize=7)\n",
    "    #plt.bar(r1,bars1,width = barWidth..)\n",
    "    ys = toPlot\n",
    "    # general layout\n",
    "    #plt.xticks([r for r in range(len(bars1))], ys,rotation='vertical')\n",
    "    #plt.yticks([r for r in range(len(bars1))], ys,rotation='vertical')\n",
    "    plt.yticks([r for r in range(len(bars1))], ys)\n",
    "    plt.title(\"Target country: \"+ t1.iloc[idx][\"ObjectiveCountry\"])\n",
    "    plt.ylabel('Features (except price)')\n",
    "    plt.xlabel(\"Importance\")\n",
    "    # Show graphic\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# radar chart to compare importances between regression and dectrees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = result.head(4)\n",
    "test = result.iloc[5]\n",
    "feats = []\n",
    "values = []\n",
    "\n",
    "genFeatures = []\n",
    "for col in result.columns:\n",
    "    if(col.startswith(\"feat_\")):\n",
    "            genFeatures.append(col)\n",
    "print(genFeatures)\n",
    "\n",
    "for col in result.columns:\n",
    "    if(col.startswith(\"feat_\")) and (test[col] != 100):\n",
    "        print(col,test[col])\n",
    "        feats.append(col)\n",
    "        values.append(test[col])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#per il radar chart, va bene probabilmente solo per la comparazione dei risultati delle importanze per linear regression e dectreeclass\n",
    "\n",
    "#oppure anche per i risultati di precision recall e f1 score?\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df = df1[[\"algorithm\"] + genFeatures]\n",
    "df = df.reset_index(drop=True)\n",
    "#df.drop([\"algorithm\"],axis=1,inplace=True)\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].replace(100,0)\n",
    "    if len(df[col].unique().tolist()) == 1 and col != \"algorithm\":\n",
    "        df.drop(col,inplace=True,axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devi costruire il dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spider(row, title):#,# color):\n",
    " \n",
    "    # number of variable\n",
    "    categories=list(df)[1:]\n",
    "    #print(categories)\n",
    "    N = len(categories)\n",
    "\n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    # Initialise the spider plot\n",
    "    ax = plt.subplot(2,2,idx+1, polar=True, )\n",
    "\n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], categories, color='grey', size=8)\n",
    "\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0.1,0.25,0.50,1], [\"0.1\",\"0.25\",\"50\",\"1\"], color=\"grey\", size=7)\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    # Ind1\n",
    "    values=df.loc[idx].drop('algorithm').values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, linewidth=1)\n",
    "    ax.fill(angles, values, alpha=0.4)\n",
    "\n",
    "    # Add a title\n",
    "    plt.title(title, size=11, y=1.1)\n",
    "    \n",
    "# ------- PART 2: Apply to all individuals\n",
    "# initialize the figure\n",
    "my_dpi=96\n",
    "plt.figure(figsize=(1000/my_dpi, 1000/my_dpi), dpi=my_dpi)\n",
    " \n",
    "# Create a color palette:\n",
    "#my_palette = plt.cm.get_cmap(\"Set2\", len(df.index))\n",
    " \n",
    "# Loop to plot\n",
    "for idx,row in df.iterrows():\n",
    "    make_spider(row,row[\"algorithm\"]) #,my_palette(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"feat_winery\"] != 0]\n",
    "df = df.reset_index(drop=True)\n",
    "print(df)\n",
    "# number of variable\n",
    "categories=list(df)[1:]\n",
    "N = len(categories)\n",
    " \n",
    "# We are going to plot the first line of the data frame.\n",
    "# But we need to repeat the first value to close the circular graph:\n",
    "values=df.loc[0].drop('algorithm').values.flatten().tolist()\n",
    "values += values[:1]\n",
    "values\n",
    " \n",
    "# What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "my_dpi=96\n",
    "plt.figure(figsize=(1000/my_dpi, 1000/my_dpi), dpi=my_dpi)\n",
    "\n",
    "# Initialise the spider plot\n",
    "ax = plt.subplot(111, polar=True)\n",
    " \n",
    "# Draw one axe per variable + add labels labels yet\n",
    "plt.xticks(angles[:-1], categories, color='grey', size=8)\n",
    " \n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([0.1,0.25,0.50,1], [\"0.1\",\"0.25\",\"0.50\",\"1\"], color=\"grey\", size=7)\n",
    "plt.ylim(0,1)\n",
    " \n",
    "# Plot data\n",
    "ax.plot(angles, values, linewidth=1, linestyle='solid')\n",
    " \n",
    "# Fill area\n",
    "ax.fill(angles, values, 'b', alpha=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot scatter plot for visualizing bins by color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot radar plot to visualize most important features for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot radar plot for features in dectree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data\n",
    "df = pd.DataFrame({\n",
    "'group': ['A','B','C','D'],\n",
    "'var1': [38, 1.5, 30, 4],\n",
    "'var2': [29, 10, 9, 34],\n",
    "'var3': [8, 39, 23, 24],\n",
    "'var4': [7, 31, 33, 14],\n",
    "'var5': [28, 15, 32, 14]\n",
    "})\n",
    " \n",
    "# ------- PART 1: Define a function that do a plot for one line of the dataset!\n",
    " \n",
    "def make_spider( row, title, color):\n",
    "    categories=list(df)[1:]\n",
    "    N = len(categories)\n",
    "\n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * math.pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    # Initialise the spider plot\n",
    "    ax = plt.subplot(2,2,row+1, polar=True, )\n",
    "\n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(math.pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], categories, color='grey', size=8)\n",
    "\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([10,20,30], [\"10\",\"20\",\"30\"], color=\"grey\", size=7)\n",
    "    plt.ylim(0,40)\n",
    "\n",
    "    # Ind1\n",
    "    values=df.loc[row].drop('group').values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, color=color, linewidth=2, linestyle='solid')\n",
    "    ax.fill(angles, values, color=color, alpha=0.4)\n",
    "\n",
    "    # Add a title\n",
    "    plt.title(title, size=11, color=color, y=1.1)\n",
    "\n",
    "# ------- PART 2: Apply to all individuals\n",
    "# initialize the figure\n",
    "my_dpi=96\n",
    "plt.figure(figsize=(1000/my_dpi, 1000/my_dpi), dpi=my_dpi)\n",
    " \n",
    "# Create a color palette:\n",
    "my_palette = plt.cm.get_cmap(\"Set2\", len(df.index))\n",
    " \n",
    "# Loop to plot\n",
    "for row in range(0, len(df.index)):\n",
    "    make_spider( row=row, title='group '+df['group'][row], color=my_palette(row))\n",
    "\n",
    "categories=list(df)[1:]\n",
    "N = len(categories)\n",
    " \n",
    "# What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "angles = [n / float(N) * 2 * math.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    " \n",
    "# Initialise the spider plot\n",
    "ax = plt.subplot(2,2,row+1, polar=True, )\n",
    " \n",
    "# If you want the first axis to be on top:\n",
    "ax.set_theta_offset(math.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    " \n",
    "# Draw one axe per variable + add labels labels yet\n",
    "plt.xticks(angles[:-1], categories, color='grey', size=8)\n",
    " \n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([10,20,30], [\"10\",\"20\",\"30\"], color=\"grey\", size=7)\n",
    "plt.ylim(0,40)\n",
    " \n",
    "# Ind1\n",
    "values=df.loc[row].drop('group').values.flatten().tolist()\n",
    "values += values[:1]\n",
    "ax.plot(angles, values, color=color, linewidth=2, linestyle='solid')\n",
    "ax.fill(angles, values, color=color, alpha=0.4)\n",
    " \n",
    "# Add a title\n",
    "plt.title(title, size=11, color=color, y=1.1)\n",
    " \n",
    "# ------- PART 2: Apply to all individuals\n",
    "# initialize the figure\n",
    "my_dpi=96\n",
    "plt.figure(figsize=(1000/my_dpi, 1000/my_dpi), dpi=my_dpi)\n",
    " \n",
    "# Create a color palette:\n",
    "my_palette = plt.cm.get_cmap(\"Set2\", len(df.index))\n",
    " \n",
    "# Loop to plot\n",
    "for row in range(0, len(df.index)):\n",
    "    make_spider( row=row, title='group '+df['group'][row], color=my_palette(row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFIER WITHOUT SPARSE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decTree(features, depth, data,Y):\n",
    "    X = data.loc[:,features]\n",
    "    test_size = 0.30\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "    y_train = list(y_train)\n",
    "    classifier = DecisionTreeClassifier(max_depth=depth)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred = classifier.predict(X_test)  \n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "    print(acc,weightedPrec)\n",
    "    #get feature importances\n",
    "    lista = []\n",
    "    for name, importance in zip(features, classifier.feature_importances_):\n",
    "        lista.append([name, importance])\n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(y_test, y_pred,labels=labels)\n",
    "    print(classification_report(y_test, y_pred, target_names=labels))\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp = wine_base\n",
    "Y = temp['points'].copy()\n",
    "nbins  = 3\n",
    "labels=[\"low\",\"medium\",\"high\"]\n",
    "Y,bins = pd.qcut(Y,nbins,labels=labels,retbins=True)   #uses quartiles and statistic stuff\n",
    "temp = temp.drop([\"points\",\"country\"],axis=1)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = temp.columns\n",
    "depth = 4\n",
    "clf = decTree(features,depth,temp,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show me the tree\n",
    "\n",
    "##### Graphviz sucks, you need to check if it's installed and it may give you problems anyway, the code below fixed it for me\"\n",
    "#### be sure that you have the package installed\n",
    "import os\n",
    "import sys\n",
    "def conda_fix(graph):\n",
    "        path = os.path.join(sys.base_exec_prefix, \"Library\", \"bin\", \"graphviz\")\n",
    "        paths = (\"dot\", \"twopi\", \"neato\", \"circo\", \"fdp\")\n",
    "        paths = {p: os.path.join(path, \"{}.exe\".format(p)) for p in paths}\n",
    "        graph.set_graphviz_executables(paths)\n",
    "import pydotplus \n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=features,  \n",
    "                         class_names=labels,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "conda_fix(graph)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier using sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparseMatrixRep(features,depth,data,test_size):\n",
    "    X = data.loc[:,features+[\"description\"]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    #compute countvectorizer\n",
    "    vect = CountVectorizer(min_df=5)\n",
    "    vect.fit(X_train['description'])\n",
    "    print(\"vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "    X_train_vectored_cv = vect.transform(X_train['description'])\n",
    "    X_train_final = X_train_vectored_cv\n",
    "    for feature in features:\n",
    "        X_train_final = hstack((X_train_final,np.array(X_train[feature])[:,None]))\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth=depth)\n",
    "    clf.fit(X_train_final, y_train)\n",
    "    \n",
    "    y_train_pred = clf.predict(X_train_final)\n",
    "    X_test_final = vect.transform(X_test['description'])\n",
    "    for feature in features:\n",
    "        X_test_final = hstack((X_test_final,np.array(X_test[feature])[:,None]))\n",
    "\n",
    "    y_test_pred = clf.predict(X_test_final)\n",
    "    print(classification_report(y_test, y_test_pred, target_names=labels))\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the input and compute\n",
    "\n",
    "features = [\"price\"] #basic #+ word + tfGroup + word2vec\n",
    "depth = 3\n",
    "test_size = 0.30\n",
    "clf = sparseMatrixRep(features,depth,wine_base,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show me the tree\n",
    "##### Graphviz sucks, you need to check if it's installed and it may give you problems anyway, the code below fixed it for me\"\n",
    "#### be sure that you have the package installed\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pydotplus \n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "\n",
    "def conda_fix(graph):\n",
    "    path = os.path.join(sys.base_exec_prefix, \"Library\", \"bin\", \"graphviz\")\n",
    "    paths = (\"dot\", \"twopi\", \"neato\", \"circo\", \"fdp\")\n",
    "    paths = {p: os.path.join(path, \"{}.exe\".format(p)) for p in paths}\n",
    "    graph.set_graphviz_executables(paths)\n",
    "    \n",
    "dot_data = tree.export_graphviz(clf, out_file=None,   \n",
    "                             class_names=labels,  \n",
    "                             filled=True, rounded=True,  \n",
    "                             special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "conda_fix(graph)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with combinations and get results dataframe (no countvect working on this as of now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with every test combination you put\n",
    "def testToDataFrame(algorithm,combination,Y,allfeats,dataset):\n",
    "    test_size = 0.30 \n",
    "    cols = [\"algorithm\",\"input\",\"precision\",\"accuracy\",\"depth\"]\n",
    "    for lab in labels:\n",
    "        cols.append(lab +\"_prec\")\n",
    "        cols.append(lab +\"_recall\")\n",
    "        cols.append(lab +\"_f1\")\n",
    "        cols.append(lab +\"_support\")\n",
    "    for el in allfeats: #controlla che allfeats vada bene, amgari fotte con l'ordine\n",
    "        cols.append(\"feat_\"+el)\n",
    "    results = pd.DataFrame()\n",
    "    row = 0\n",
    "    comb = 0\n",
    "    for el in combination[\"args\"]: \n",
    "        for depth in combination[\"depth\"]:\n",
    "            row = row + 1\n",
    "            X = dataset.loc[:,el]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "            if algorithm == \"decTree\":\n",
    "                classifier = DecisionTreeClassifier(max_depth=depth)\n",
    "            else:\n",
    "                classifier = RandomForestClassifier(max_depth=depth,n_estimators = estimators)\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_pred = classifier.predict(X_test)  \n",
    "            acc = accuracy_score(y_test,y_pred)\n",
    "            weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")        \n",
    "            data = [algorithm,el,weightedPrec,acc,depth]\n",
    "            precision,recall,fscore,support = precision_recall_fscore_support(y_test, y_pred)\n",
    "            for i in range(0,len(labels)):\n",
    "                data.append(precision[i])\n",
    "                data.append(recall[i])\n",
    "                data.append(fscore[i])\n",
    "                data.append(support[i])\n",
    "            #for lab in labels:\n",
    "            \n",
    "             #   data.append(rep[lab].precision)     #ORDER IS VERY IMPORTANT\n",
    "              #  data.append(rep[lab].recall)\n",
    "               # data.append(rep[lab].f1-score)\n",
    "                #data.append(rep[lab].support)\n",
    "            temp = {}\n",
    "            c = zip(el,classifier.feature_importances_)\n",
    "            counter = 0\n",
    "            for name,importance in c:\n",
    "                if importance > 0:\n",
    "                    temp[name] = importance\n",
    "                    counter += 1\n",
    "            data.append(counter)\n",
    "            for feat in allfeats:\n",
    "                if feat not in el:\n",
    "                    data.append(100) #100 is an impossible value not to be taken into account\n",
    "                else:\n",
    "                    data.append(temp[feat])\n",
    "            df2 = pd.DataFrame([data],columns=cols)\n",
    "            results = results.append(df2,ignore_index=True)\n",
    "        comb = comb + 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [[\"price\"],[\"price\",\"word_count\"],basic,basic+tfGroup, basic+word2vec,basic+word2vec+tfGroup,word2vec,tfGroup,word2vec+tfGroup]\n",
    "allfeatures = basic + word + word2vec + tfGroup \n",
    "decTreeCombinations = {\"depth\":[2,3,4,5],\"args\":args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = testToDataFrame(\"decTree\",decTreeCombinations,Y,allfeatures,wine_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort_values([\"precision\",'depth'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.iloc[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.iloc[17]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
